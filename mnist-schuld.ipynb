{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLOXFOT5Q40E"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "iiQkM5ZgQ8r2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6331ZSsQGY3"
   },
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9Jcnb8bQQyd"
   },
   "source": [
    "Based on https://www.tensorflow.org/quantum/tutorials/mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udLObUVeGfTs"
   },
   "source": [
    "We build a quantum neural network (QNN) to classify a simplified version of MNIST, similar to the approach used in <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a>. The performance of the quantum neural network on this classical data problem is compared with a classical neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X35qHdh5Gzqg"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TorxE5tnkvb2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboard_plugin_profile==2.3.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (2.3.0)\n",
      "Requirement already satisfied: gviz-api>=1.9.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tensorboard_plugin_profile==2.3.0) (1.9.0)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tensorboard_plugin_profile==2.3.0) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tensorboard_plugin_profile==2.3.0) (1.15.0)\n",
      "Requirement already satisfied: werkzeug>=0.11.15 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tensorboard_plugin_profile==2.3.0) (1.0.1)\n",
      "Requirement already satisfied: protobuf>=3.6.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tensorboard_plugin_profile==2.3.0) (3.13.0)\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -q tensorflow==2.3.1\n",
    "!python3.8 -m pip install -q tensorflow==2.4.1\n",
    "!python3.8 -m pip install tensorboard_plugin_profile==2.3.0\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxkQA6oblNqI"
   },
   "source": [
    "Install TensorFlow Quantum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saFHsRDpkvkH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tfq-nightly in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (0.5.0.dev20210516)\n",
      "Requirement already satisfied: protobuf==3.13.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (3.13.0)\n",
      "Collecting grpcio==1.30.0\n",
      "  Using cached grpcio-1.30.0-cp38-cp38-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "Requirement already satisfied: googleapis-common-protos==1.52.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (1.52.0)\n",
      "Requirement already satisfied: sympy==1.5 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (1.5)\n",
      "Requirement already satisfied: cirq==0.11.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: google-api-core==1.21.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (1.21.0)\n",
      "Requirement already satisfied: google-auth==1.18.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (1.18.0)\n",
      "Requirement already satisfied: cirq-google==0.11.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq==0.11.0->tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: cirq-core==0.11.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq==0.11.0->tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (3.7.4.3)\n",
      "Requirement already satisfied: pandas in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.2.3)\n",
      "Requirement already satisfied: scipy in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.6.2)\n",
      "Requirement already satisfied: networkx~=2.4 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.5.1)\n",
      "Requirement already satisfied: sortedcontainers~=2.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.3.0)\n",
      "Requirement already satisfied: tqdm in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.59.0)\n",
      "Requirement already satisfied: numpy~=1.16 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.19.2)\n",
      "Requirement already satisfied: requests~=2.18 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.25.1)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (3.3.4)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (1.15.0)\n",
      "Requirement already satisfied: pytz in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (2021.1)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (0.2.8)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (4.7.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from sympy==1.5->tfq-nightly) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.8.1)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.4.7)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (8.2.0)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from networkx~=2.4->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.4.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth==1.18.0->tfq-nightly) (0.4.8)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.26.4)\n",
      "Installing collected packages: grpcio\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires grpcio~=1.32.0, but you have grpcio 1.30.0 which is incompatible.\u001b[0m\n",
      "Successfully installed grpcio-1.30.0\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -q tensorflow-quantum\n",
    "!python3.8 -m pip install tfq-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdgMMZEBGqyl"
   },
   "source": [
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enZ300Bflq80",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "import datetime\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit\n",
    "\n",
    "# set the random seed\n",
    "tf.random.set_seed(137)\n",
    "np.random.seed(137)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b08Mmbs8lr81"
   },
   "source": [
    "## 1. Load the data\n",
    "\n",
    "In this tutorial you will build a binary classifier to distinguish between the digits 3 and 6, following <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> This section covers the data handling that:\n",
    "\n",
    "- Loads the raw data from Keras.\n",
    "- Filters the dataset to only 3s and 6s.\n",
    "- Downscales the images so they fit can fit in a quantum computer.\n",
    "- Removes any contradictory examples.\n",
    "- Converts the binary images to Cirq circuits.\n",
    "- Converts the Cirq circuits to TensorFlow Quantum circuits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDUdGxn-ojgy"
   },
   "source": [
    "### 1.1 Load the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZyGXlaKojgz"
   },
   "source": [
    "Load the MNIST dataset distributed with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9OSExvCojg0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original training examples: 60000\n",
      "Number of original test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZpbygdGojg3"
   },
   "source": [
    "Filter the dataset to keep just the 3s and 6s,  remove the other classes. At the same time convert the label, `y`, to boolean: `True` for `3` and `False` for 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOw68cCZojg4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_36(x, y):\n",
    "    keep = (y == 3) | (y == 6)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == 3\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-XEU8egGL6q",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered training examples: 12049\n",
      "Number of filtered test examples: 1968\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = filter_36(x_train, y_train)\n",
    "x_test, y_test = filter_36(x_test, y_test)\n",
    "\n",
    "print(\"Number of filtered training examples:\", len(x_train))\n",
    "print(\"Number of filtered test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wyiaP0Xojg_"
   },
   "source": [
    "Show the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5STP7MbojhA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f914af68190>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train[0, :, :, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNS9sVPQojhC"
   },
   "source": [
    "### 1.2 Downscale the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmmtplIFGL6t"
   },
   "source": [
    "An image size of 28x28 is much too large for current quantum computers. Resize the image down to 4x4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbhUdBFWojhE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
    "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOMd7zIjGL6x"
   },
   "source": [
    "Again, display the first training example—after resize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIYOtCRIGL6y",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f914be6ddc0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATkAAAD8CAYAAAAMs9NCAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8QVMy6AAAACXBIWXMAAAsTAAALEwEAmpwYAAAVdklEQVR4nO3df6xfdX3H8eeLWkQE1rE66UpFtnUuaiZgLRD2A/FX2zDrEsyKiziiuYHAgokmEpdAzP7ZssRsBKS7UQIkDGIUsSNFhgYHRovUplRLRW/QyB2NDaCFCgK997U/zin78uX7vfdczrn3e+65r0dycr/nez79fD63pG8+5/NTtomI6KqjRl2BiIj5lCAXEZ2WIBcRnZYgFxGdliAXEZ2WIBcRnVYryEk6UdI9kn5a/vzdIel+LumHknZL2lmnzIjoLkk3SDog6UdDnkvSNZImJO2RdMZsedZtyV0JfMv2WuBb5f0w77Z9mu11NcuMiO66Edgww/ONwNryGgOuny3DukFuM3BT+fkm4EM184uIJcz2fcBTMyTZDNzswg5ghaRVM+X5mpp1eqPt/WXl9kv6/SHpDPy3JAP/YXt8WIaSxigiNMtY9s5jOaFmFSNimN/yG17w86qTxwfe/Xo/+dRUpbQ/2PP8XuC3PV+NzxQPBlgNPNZzP1l+t3/YH5g1yEn6JnDSgEf/OIeKnWP78TII3iPpx2XEfoXyFx4HOEEn+ky9Zw7FRMRcPOBv1c7jyaem+P7db6qUdtmqn/62ZpfVoIA849rUWYOc7fcOLU36paRVZStuFXBgSB6Plz8PSPoasB4YGOQiYnExMM30QhU3CazpuT8ZeHymP1C3T24b8LHy88eAr/cnkPR6Sccf+Qy8Hxg4chIRi48xL3qq0tWAbcBF5SjrWcDBI11mw9Ttk/tn4MuSPg78AvgwgKQ/AL5oexPwRuBrko6U95+2v1Gz3IhokaZacpJuBc4FVkqaBK4GlgPY3gpsBzYBE8CzwMWz5VkryNl+EnhFp1n5erqp/Pwo8I465UREexkz1dCWbbYvnOW5gcvmkmfdllxEBNMz9/2PVIJcRNRiYCpBLiK6LC25iOgsAy+2+BiFBLmIqMU4r6sR0WGGqfbGuAS5iKinWPHQXglyEVGTmBq4pLQdEuQiopZi4CFBLiI6qpgnlyAXER02nZZcRHRVWnIR0WlGTLX44L8EuYioLa+rEdFZRrzgZaOuxlAJchFRSzEZOK+rEdFhGXiIiM6yxZTb25JrpGaSNkh6RNKEpCsHPJeka8rneySd0US5EdEO06jSNQq1W3KSlgHXAe+jOC7sQUnbbD/ck2wjsLa8zgSuL39GxCJXDDy096WwiZbcemDC9qO2XwBuAzb3pdkM3OzCDmBFeU5rRCxyRwYeqlyj0ESpq4HHeu4ny+/mmiYiFqkpq9I1Ck20MQfVvH8LvSppioTSGDAGcAzH1qtZRMy7pbDiYRJY03N/MvD4q0gDgO1xYBzgBJ3Y4v1GI+KI6Y6Prj4IrJV0qqSjgS3Atr4024CLylHWs4CDtvc3UHZEjFixQP+oStco1G7J2T4s6XLgbmAZcIPtvZIuKZ9vBbYDm4AJ4Fng4rrlRkQ7GPFi15d12d5OEch6v9va89nAZU2UFRHtYtPqycDtndwSEYvE6Cb6VpEgFxG1mLTkIqLjuj6FJCKWMKNsmhkR3VUcSdjeUNLemkXEIpHDpSOiw0y7VzwkyEVEbW1uybU3/EbEomCLaR9V6ZpNhQ14f0fSf0l6SNJeSbOunkpLLiJqKQYe6i/rqrgB72XAw7b/WtIbgEck3VLuZTlQglxE1NTYGQ8vbcALIOnIBry9Qc7A8ZIEHAc8BRyeKdMEuYiopRh4qNwnt1LSzp778XJ7NRi8uW7/MQnXUuxq9DhwPPC3tqdnKjBBLiJqm8OKhydsrxvyrMrmuh8AdgPnAX8E3CPpfttPDyswAw8RUcuRFQ9VrllU2Vz3YuD28ryYCeBnwJ/OlGmCXETU1tBBNlU24P0F8B4ASW8E3gI8OlOmeV2NiFpseHG6fnup4ga8/wTcKOmHFK+3n7H9xEz5JshFRC3F62ozL4UVNuB9HHj/XPJMkIuI2tq84iFBLiJqmeMUkgXXSBuzwlKMcyUdlLS7vK5qotyIaIPmlnXNh9otuYpLMQDut31+3fIion26fsZDlaUYsUQ8MXb2qKswL1aOf2/UVWitYnS1vUcSNtF+HLQUY/WAdGeXOwfcJeltwzKTNCZpp6SdL/J8A9WLiPnU4GTgedFES67KUoxdwCm2D0naBNwBrB2UWbmObRzgBJ3Yn09EtFCbX1ebaMnNuhTD9tO2D5WftwPLJa1soOyIGLEjo6ttbck1EeRmXYoh6aRyaxQkrS/LfbKBsiOiBTo9ulpxKcYFwKWSDgPPAVts51U0ogNscbjrZzxUWIpxLcU+UBHRQW2eDJwVDxFRS9tXPCTIRURtCXIR0VlH5sm1VYJcRNTW5nlyCXIRUYsNhxvYNHO+JMhFRG15XY2IzkqfXER0nhPkIqLLMvAQEZ1lp08uIjpNTGV0NSK6LH1yEdFZWbsaEd3mol+urRLkIqK2jK5GRGc5Aw8R0XV5XY2ITmvz6GojbUxJN0g6IOlHQ55L0jWSJiTtkXRGE+VGxOjZRZCrco1CUy/SNwIbZni+keKc1bXAGHB9Q+VGRAt0/UhCbN8HPDVDks3AzS7sAFZIWtVE2RExena1axQWqk9uNfBYz/1k+d3+/oSSxihaexzDsQtSuYh49YyYbvHo6kLVbFA7dWBctz1ue53tdct57TxXKyKa4IrXKCxUkJsE1vTcnww8vkBlR8R8anDgQdIGSY+Ug5RXDklzrqTdkvZK+p/Z8lyoILcNuKgcZT0LOGj7Fa+qEbFINdCUk7QMuI5ioPKtwIWS3tqXZgXwBeCDtt8GfHi2qjXSJyfpVuBcYKWkSeBqYDmA7a3AdmATMAE8C1zcRLkR0Q4NTQ9ZD0zYfhRA0m0Ug5YP96T5CHC77V8U5frAbJk2EuRsXzjLcwOXNVFWRLSLgenpykFupaSdPffjtsfLz4MGKM/s+/N/AiyX9G3geODfbd88U4FZ8RAR9Rio3pJ7wva6Ic+qDFC+Bngn8B7gdcD3JO2w/ZNhBSbIRURtDc2BqzJAOUkRKH8D/EbSfcA7gKFBrr2TWyJi8WhmDsmDwFpJp0o6GthCMWjZ6+vAX0h6jaRjKV5n982UaVpyEVFTM+tSbR+WdDlwN7AMuMH2XkmXlM+32t4n6RvAHmAa+KLtgWvmj0iQi4j6Gprpa3s7xWyM3u+29t3/K/CvVfNMkIuIegyuPrq64BLkIqIBCXIR0WXZGTgiOi1BLiI6a26TgRdcglxE1JaDbCKi2zK6GhFdprTkIqKzRrntbwUJchFRkzLwEBEdl5ZcRHTa9KgrMFyCXETU0/J5co3sJyfpBkkHJA3c8qQ8XedgecLObklXNVFuRLSDXO0ahaZacjcC1wIz7bV+v+3zGyovItqkxX1yjbTkbN8HPNVEXhERTVrIPrmzJT1EsWf7p23vHZRI0hgwBnAMxy5g9aIJ3736mlFXYV58cPxdo65Cq2UyMOwCTrF9SNIm4A5g7aCE5fFk4wAn6MQW/9VFBFCeSdjxgYfZ2H7a9qHy83aKcxNXLkTZEbEAmjnIZl4sSJCTdJIklZ/Xl+U+uRBlR8T86/zoqqRbgXMpTseeBK4GlsNLh1BcAFwq6TDwHLDFbvPmLBExJy3+19xIkLN94SzPr6WYYhIRXdT1IBcRS9coX0WrSJCLiPpaPLqaIBcRtaUlFxHdliAXEZ2VPrmI6LwEuYjoMrV408wFWfEQETEqaclFRH15XY2IzsrAQ0R0XoJcRHRaglxEdJXI6GpEdFnFveSq9NtJ2iDpEUkTkq6cId27JE1JumC2PBPkIqK+BnYGlrQMuA7YCLwVuFDSW4ek+xfg7ipVS5CLiPqa2f58PTBh+1HbLwC3AZsHpPsH4KvAgSpVS5CLiNrm8Lq6UtLOnmusJ5vVwGM995Pld/9fjrQa+Btga9W6ZeAhIuqrPrr6hO11Q54N2pSuP+d/Az5je6o8NmZWtVtyktZIulfSPkl7JV0xII0kXVN2Ju6RdEbdciOiJVyMrla5ZjEJrOm5P5ninOZe64DbJP2c4uyYL0j60EyZNtGSOwx8yvYuSccDP5B0j+2He9JspDhndS1wJnB9+TMiuqCZeXIPAmslnQr8L7AF+MjLirFPPfJZ0o3AnbbvmCnT2i052/tt7yo/PwPso+89mqLz8GYXdgArJK2qW3ZEtEMTU0hsHwYupxg13Qd82fZeSZdIuuTV1q3RPjlJbwZOBx7oezSsQ3H/gDzGgDGAYzi2yepFxHxpaMVDefj89r7vBg4y2P77Knk2Nroq6TiKYd1P2n66//GAPzLwr8X2uO11ttct57VNVS8i5kvV6SOL/HDp5RQB7hbbtw9IUqVDMSIWIdHuXUiaGF0V8CVgn+3PD0m2DbioHGU9Czho+xWvqhGxODW1rGs+NNGSOwf4KPBDSbvL7z4LvAleep/eDmwCJoBngYsbKDci2qLFLbnaQc72dxjc59abxsBldcuKiJbqcpCLiCUuOwNHROclyEVEl7V508wEuYioLa+rEdFdI5zoW0WCXETUlyAXEV3V9hUPCXIRUZum2xvlEuQiop70yUVE1+V1NSK6LUEuIrosLbmI6LYEuYjoLGdZV0R0WObJRUT3ub1RLkEuImpLSy4iuqvlk4GbOMhmjaR7Je2TtFfSFQPSnCvpoKTd5XVV3XIjoj00Xe0ahSZacoeBT9neJel44AeS7rH9cF+6+22f30B5EdEynR5dLY8W3F9+fkbSPmA10B/kIqKLzNIZeJD0ZuB04IEBj8+W9BDFodKftr13SB5jwBjAMRzbZPVa49A3/nDUVZg3H1w96hrEKCyJgQdJxwFfBT5p++m+x7uAU2wfkrQJuANYOygf2+PAOMAJOrHFf3UR8ZIW/0utPfAAIGk5RYC7xfbt/c9tP237UPl5O7Bc0somyo6I0ToyGbjKNQq1W3KSBHwJ2Gf780PSnAT80rYlracIrk/WLTsiWsDu/KaZ5wAfBX4oaXf53WeBNwHY3gpcAFwq6TDwHLDFbnFPZUTMTYv/NTcxuvodihbrTGmuBa6tW1ZEtNOSGHiIiCXKQMdfVyNiqWtvjGtmdDUilramRlclbZD0iKQJSVcOeP53kvaU13clvWO2PNOSi4jamhhdlbQMuA54HzAJPChpW98S0Z8Bf2X7V5I2UsypPXOmfNOSi4h6PIdrZuuBCduP2n4BuA3Y/LKi7O/a/lV5uwM4ebZM05KLiFqKycCVW3IrJe3suR8vVzlBseb9sZ5nk8zcSvs4cNdsBSbIRUR91XchecL2uiHPBk1FGxg9Jb2bIsj9+WwFJshFRG1zaMnNZBJY03N/MsWGHi8vS/oz4IvARtuzrpxKn1xE1NNcn9yDwFpJp0o6GtgCbOtNIOlNwO3AR23/pEr10pKLiJqaWbtq+7Cky4G7gWXADbb3SrqkfL4VuAr4PeALxbJ5Ds/w+gskyEVEExpail7uUrS977utPZ8/AXxiLnkmyEVEPTlcOiI6r8WbCiXIRUR97Y1xCXIRUZ+m2/u+miAXEfWYuUwGXnAJchFRi3BTk4HnRYJcRNTX4iBXe8WDpGMkfV/SQ5L2SvrcgDSSdE25R9QeSWfULTciWsSudo1AEy2554HzyjNVlwPfkXSX7R09aTZSnLO6lmJXgeuZZQ+oiFgkut4nV566dai8XV5e/SF7M3BzmXaHpBWSVtneX7f8iBi9No+uNnW49LLyOMIDwD22H+hLMmifqNVNlB0Ro1bxVXVEr6uNBDnbU7ZPo9gaZb2kt/clmcs+UWOSdkra+SLPN1G9iJhPpvtB7gjbvwa+DWzoe1Rpn6gyj3Hb62yvW85rm6xeRMyX6YrXCDQxuvoGSSvKz68D3gv8uC/ZNuCicpT1LOBg+uMiukN2pWsUmhhdXQXcVJ60cxTwZdt39u0BtR3YBEwAzwIXN1BuRLRFi+fJNTG6ugc4fcD3vXtAGbisblkR0UI2TLV3dDUrHiKivi635CIiEuQiorsMNHDGw3xJkIuImgxOn1xEdJXJwENEdFz65CKi0xLkIqK7RrcutYoEuYiox0CLt1pKkIuI+tKSi4juyrKuiOgygzNPLiI6LSseIqLT0icXEZ1lZ3Q1IjouLbmI6C7jqalRV2KoBLmIqCdbLUVE57V4CkkTp3UdI+n7kh6StFfS5wakOVfSQUm7y+uquuVGRDsY8LQrXbORtEHSI5ImJF054LkkXVM+3yPpjNnybKIl9zxwnu1DkpYD35F0l+0dfenut31+A+VFRJu4mU0zyxP/rgPeR3FW84OSttl+uCfZRmBteZ0JXF/+HKqJ07oMHCpvl5dXe1/QI6JxDQ08rAcmbD8KIOk2YDPQG+Q2AzeXcWeHpBWSVs10jnMjfXJlBP4B8MfAdbYfGJDsbEkPAY8Dn7a9d0heY8BYeXvom/7KI03UsYKVwBMLUtIHFqSUIxbu91pYXf29YGF/t1PqZvAMv7r7m/7KyorJj5G0s+d+3PZ4+Xk18FjPs0le2UoblGY1ML9BzvYUcJqkFcDXJL3d9o96kuwCTilfaTcBd1A0NwflNQ6MD3o2nyTttL1uocudb/m9Fp/F9rvZ3tBQVhqU/atI8zK1Bx5eVpL9a+DbwIa+75+2faj8vB1YLqlq5I+IpWESWNNzfzLFm99c07xME6OrbyhbcEh6HfBe4Md9aU6SpPLz+rLcJ+uWHRGd8iCwVtKpko4GtgDb+tJsAy4qR1nPAg7O1B8HzbyurgJuKvvljgK+bPtOSZcA2N4KXABcKukw8Bywpew4bJMFf0VeIPm9Fp8u/25D2T4s6XLgbmAZcIPtvX2xZDuwCZgAngUuni1ftS/WREQ0p9E+uYiItkmQi4hOW/JBbrZlJIuVpBskHZD0o9lTLx6S1ki6V9K+chnhFaOuUxOqLI+MV2dJ98mVgyU/oWcZCXBh3zKSRUnSX1KsRLnZ9ttHXZ+mSFoFrLK9S9LxFJPQP7TY/5uVsw9e37s8ErhiwPLImKOl3pJ7aRmJ7ReAI8tIFj3b9wFPjboeTbO93/au8vMzwD6KGe+LmgtZHjkPlnqQG7ZEJBYBSW8GTgcGLSNcdCQtk7QbOADcM2R5ZMzRUg9yc14iEu0g6Tjgq8AnbT896vo0wfaU7dMoZvGvl9SZboZRWupBbs5LRGL0yj6rrwK32L591PVp2rDlkfHqLPUgV2UZSbRI2UH/JWCf7c+Puj5NqbI8Ml6dJR3kbB8Gjiwj2UexJG3gFlCLjaRbge8Bb5E0Kenjo65TQ84BPgqc17PT9KZRV6oBq4B7Je2h+J/vPbbvHHGdOmFJTyGJiO5b0i25iOi+BLmI6LQEuYjotAS5iOi0BLmI6LQEuYjotAS5iOi0/wO4vMxZdG+6wwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGeF1_qtojhK"
   },
   "source": [
    "### 1.3 Remove contradictory examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZLkq2yeojhL"
   },
   "source": [
    "From section *3.3 Learning to Distinguish Digits* of <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a>, filter the dataset to remove images that are labeled as belonging to both classes.\n",
    "\n",
    "This is not a standard machine-learning procedure, but is included in the interest of following the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqOPW0C7ojhL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_contradicting(xs, ys):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    orig_x = {}\n",
    "    # Determine the set of labels for each unique image:\n",
    "    for x,y in zip(xs,ys):\n",
    "       orig_x[tuple(x.flatten())] = x\n",
    "       mapping[tuple(x.flatten())].add(y)\n",
    "    \n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    for flatten_x in mapping:\n",
    "      x = orig_x[flatten_x]\n",
    "      labels = mapping[flatten_x]\n",
    "      if len(labels) == 1:\n",
    "          new_x.append(x)\n",
    "          new_y.append(next(iter(labels)))\n",
    "      else:\n",
    "          # Throw out images that match more than one label.\n",
    "          pass\n",
    "    \n",
    "    num_uniq_3 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
    "    num_uniq_6 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
    "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
    "\n",
    "    print(\"Number of unique images:\", len(mapping.values()))\n",
    "    print(\"Number of unique 3s: \", num_uniq_3)\n",
    "    print(\"Number of unique 6s: \", num_uniq_6)\n",
    "    print(\"Number of unique contradicting labels (both 3 and 6): \", num_uniq_both)\n",
    "    print()\n",
    "    print(\"Initial number of images: \", len(xs))\n",
    "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
    "    \n",
    "    return np.array(new_x), np.array(new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMOiJfz_ojhP"
   },
   "source": [
    "The resulting counts do not closely match the reported values, but the exact procedure is not specified.\n",
    "\n",
    "It is also worth noting here that applying filtering contradictory examples at this point does not totally prevent the model from receiving contradictory training examples: the next step binarizes the data which will cause more collisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpnsAssWojhP",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 10387\n",
      "Number of unique 3s:  4912\n",
      "Number of unique 6s:  5426\n",
      "Number of unique contradicting labels (both 3 and 6):  49\n",
      "\n",
      "Initial number of images:  12049\n",
      "Remaining non-contradicting unique images:  10338\n"
     ]
    }
   ],
   "source": [
    "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1z8J7OyDojhV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
    "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10538, 4, 4, 1)\n",
      "(10538,)\n"
     ]
    }
   ],
   "source": [
    "# Duplicate some entries to illustrate the effects of dropout! Run this cell only if testing dropout\n",
    "NUM_DUPLICATE = 200\n",
    "\n",
    "for i in range(NUM_DUPLICATE):\n",
    "    x_train_nocon = np.insert(x_train_nocon, 0, x_train_bin[0], axis=0)\n",
    "    y_train_nocon = np.insert(y_train_nocon, 0, y_train_nocon[0], axis=0)\n",
    "print(x_train_nocon.shape)\n",
    "print(y_train_nocon.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ5NVaPojhT"
   },
   "source": [
    "### 1.4 Encode the data as quantum circuits\n",
    "\n",
    "To process images using a quantum computer, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed representing each pixel with a qubit, with the state depending on the value of the pixel. The first step is to convert to a binary encoding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ5NVaPojhU"
   },
   "source": [
    "If you were to remove contradictory images at this point you would be left with only 193, likely not enough for effective training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1z8J7OyDojhW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 193\n",
      "Number of unique 3s:  32\n",
      "Number of unique 6s:  37\n",
      "Number of unique contradicting labels (both 3 and 6):  124\n",
      "\n",
      "Initial number of images:  10338\n",
      "Remaining non-contradicting unique images:  69\n"
     ]
    }
   ],
   "source": [
    "_ = remove_contradicting(x_train_bin, y_train_nocon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLyxS9KlojhZ"
   },
   "source": [
    "The qubits at pixel indices with values that exceed a threshold, are rotated through an $X$ gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOu_3-3ZGL61",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_circuit(image):\n",
    "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
    "    values = np.ndarray.flatten(image)\n",
    "    qubits = cirq.GridQubit.rect(4, 4)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(values):\n",
    "        if value:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "    return circuit\n",
    "\n",
    "\n",
    "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
    "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSCXqzOzojhd"
   },
   "source": [
    "Here is the circuit created for the first example (circuit diagrams do not show qubits with zero gates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3POmUEUojhe",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"164.49359375\" height=\"100.0\"><line x1=\"32.246796875\" x2=\"134.49359375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"134.49359375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"55.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"74.49359375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"94.49359375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"74.49359375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"94.49359375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f914bd6ce80>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(x_train_circ[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEQMxCcBojhg"
   },
   "source": [
    "Compare this circuit to the indices where the image value exceeds the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBIsiXdtojhh",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [3, 1]])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_img = x_train_bin[0,:,:,0]\n",
    "indices = np.array(np.where(bin_img)).T\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWZ24w1Oojhk"
   },
   "source": [
    "Convert these `Cirq` circuits to tensors for `tfq`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZStEMk4ojhk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
    "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4USiqeOqGL67"
   },
   "source": [
    "## 2. Quantum neural network\n",
    "\n",
    "There is little guidance for a quantum circuit structure that classifies images. Since the classification is based on the expectation of the readout qubit, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose using two qubit gates, with the readout qubit always acted upon. This is similar in some ways to running small a <a href=\"https://arxiv.org/abs/1511.06464\" class=\"external\">Unitary RNN</a> across the pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Helper functions for Tensorboard.\n",
    "\n",
    "\n",
    "- The integer values of samples, so that you can create histograms of the distribution.\n",
    "- The linear XEB fidelity estimate of a set of samples, to give some indication of how \"truly quantum random\" the samples are.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function\n",
    "def bits_to_ints(bits):\n",
    "    \"\"\"Convert tensor of bitstrings to tensor of ints.\"\"\"\n",
    "    sigs = tf.constant([1 << i for i in range(N_QUBITS)], dtype=tf.int32)\n",
    "    rounded_bits = tf.clip_by_value(tf.math.round(\n",
    "        tf.cast(bits, dtype=tf.dtypes.float32)), clip_value_min=0, clip_value_max=1)\n",
    "    return tf.einsum('jk,k->j', tf.cast(rounded_bits, dtype=tf.dtypes.int32), sigs)\n",
    "\n",
    "@tf.function\n",
    "def xeb_fid(bits):\n",
    "    \"\"\"Compute linear XEB fidelity of bitstrings.\"\"\"\n",
    "    final_probs = tf.squeeze(\n",
    "        tf.abs(tfq.layers.State()(REFERENCE_CIRCUIT).to_tensor()) ** 2)\n",
    "    nums = bits_to_ints(bits)\n",
    "    return (2 ** N_QUBITS) * tf.reduce_mean(tf.gather(final_probs, nums)) - 1.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knIzawEeojho"
   },
   "source": [
    "### 2.1 Build the model circuit\n",
    "\n",
    "This following example shows this layered approach. Each layer uses *n* instances of the same gate, with each of the data qubits acting on the readout qubit.\n",
    "\n",
    "Start with a simple class that will add a layer of these gates to a circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hjxxgU5ojho",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([cirq.X, cirq.XX, cirq.Y, cirq.YY, cirq.Z, cirq.ZZ, cirq.H, cirq.CZ, cirq.CNOT, cirq.SWAP, cirq.ISWAP, cirq.PhasedXPowGate(phase_exponent=0.123), cirq.PhasedISwapPowGate(phase_exponent=0.123), cirq.FSimGate(theta=0.123, phi=0.456), cirq.I])\n",
      "dict_keys([cirq.depolarize(p=0.01), cirq.asymmetric_depolarize(error_probabilities={'I': 0.94, 'X': 0.01, 'Y': 0.02, 'Z': 0.03}), cirq.generalized_amplitude_damp(p=0.01,gamma=0.02), cirq.amplitude_damp(gamma=0.01), cirq.ResetChannel(), cirq.phase_damp(gamma=0.01), cirq.phase_flip(p=0.01), cirq.bit_flip(p=0.01)])\n"
     ]
    }
   ],
   "source": [
    "print(tfq.util.get_supported_gates().keys())\n",
    "print(tfq.util.get_supported_channels().keys())\n",
    "\n",
    "class CircuitLayerBuilder():\n",
    "    def __init__(self, circuit, data_qubits, readout, blocks,repeat_dropout=0, overlap_dropout=False):\n",
    "        \n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "        self.curr_layer_id = 0\n",
    "        self.circuit = circuit\n",
    "        # for schuld impelmentation\n",
    "        self.blocks  = blocks\n",
    "        \n",
    "        # dropout\n",
    "        self.dropped_out_qubit_ids = []\n",
    "        self.dropout_blacklist = []\n",
    "        \n",
    "        self.overlap_dropout = overlap_dropout\n",
    "        \n",
    "        if repeat_dropout < 1:\n",
    "            repeat_dropout = 1\n",
    "        if overlap_dropout:\n",
    "            for _ in range(repeat_dropout - 1):\n",
    "                # We will be dequeing from this on each rebuild;\n",
    "                # so, each qubit will be in the list for repeat_dropout rebuilds.\n",
    "                self.dropped_out_qubit_ids.append(len(self.data_qubits))\n",
    "            self.delay_next_dropout = 1\n",
    "        else:\n",
    "            # if not overlapping, delay for as long as we're repeating\n",
    "            self.delay_next_dropout = repeat_dropout\n",
    "            \n",
    "        self.delay_next_dropout_i = 0 # try to dropout immediately\n",
    "        \n",
    "        # maps str(symbol) to (is_dropped_out, weight)\n",
    "        self.symbol_map = {}\n",
    "        \n",
    "        self.drop_out_applied = False\n",
    "        \n",
    "    def rebuild(self, circuit, data_qubits, readout, computed_weights, preserve_dropout=False):\n",
    "        # prev_weights is the result of get_weights from the prior epoch.\n",
    "        \n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "        self.curr_layer_id = 0\n",
    "        self.circuit = circuit\n",
    "        \n",
    "        if preserve_dropout:\n",
    "            if self.overlap_dropout and len(self.dropped_out_qubit_ids) > 0 and self.drop_out_applied:\n",
    "                # Dropping first element. This is either padding, or an actual id that we want to stop dropping out from here on.\n",
    "                dropped_id = self.dropped_out_qubit_ids.pop(0)\n",
    "                self.dropout_blacklist.append(dropped_id)\n",
    "        else:\n",
    "            self.dropout_blacklist = []\n",
    "            self.dropped_out_qubit_ids = []\n",
    "        \n",
    "        if self.delay_next_dropout_i > 0:\n",
    "            self.delay_next_dropout_i -= 1\n",
    "        \n",
    "        if self.delay_next_dropout_i == 0 and not self.overlap_dropout:\n",
    "            # Dropout finished for this qubit!\n",
    "            assert len(self.dropped_out_qubit_ids) <= 1\n",
    "            if len(self.dropped_out_qubit_ids) == 1:\n",
    "                self.dropout_blacklist.append(self.dropped_out_qubit_ids[0])\n",
    "            self.dropped_out_qubit_ids = []\n",
    "        \n",
    "        self.drop_out_applied = False\n",
    "        \n",
    "        print('self.dropped_out_qubit_ids = ')\n",
    "        print(self.dropped_out_qubit_ids)\n",
    "        \n",
    "        j = 0\n",
    "        \n",
    "        #print('Rebuilding; prev self.symbol_map:')\n",
    "        #print(self.symbol_map)\n",
    "        \n",
    "        for k in sorted(self.symbol_map.keys()):\n",
    "            prev_is_dropped_out, _ = self.symbol_map[k]\n",
    "            if not prev_is_dropped_out:\n",
    "                # Re-use the prev weight. This isn't directly used as TFQ inputs, but we later use it to generate\n",
    "                # sane inputs for set_weights().\n",
    "                # Also, is-dropped-out is True by default to handle the case when a rebuilt circuit might not add a layer for some reason\n",
    "                self.symbol_map[k] = (True, computed_weights[j])\n",
    "\n",
    "                # prev_weights is a list that only has entries for non-dropped-out elems\n",
    "                j += 1\n",
    "                \n",
    "        #print('Rebuilding done; updated self.symbol_map:')\n",
    "        #print(self.symbol_map)\n",
    "    \n",
    "    def add_layer(self, gate, blocks=None,apply_dropout=False):\n",
    "        # at most one dropped qubit added per layer\n",
    "        if apply_dropout and self.curr_layer_id > 0 and self.delay_next_dropout_i == 0:\n",
    "            while True:\n",
    "                rand_id = np.random.randint(0, len(self.data_qubits) * 2 + 1)\n",
    "                if rand_id >= len(self.data_qubits):\n",
    "                    rand_id = len(self.data_qubits)\n",
    "                # Kinda hacky, blacklist qubits that we dropped out already\n",
    "                if rand_id not in self.dropout_blacklist or rand_id == len(self.data_qubits):\n",
    "                    break\n",
    "            print('self.dropout_blacklist =')\n",
    "            print(self.dropout_blacklist)\n",
    "            #print(rand_id)\n",
    "            if rand_id not in self.dropped_out_qubit_ids and rand_id != len(self.data_qubits):\n",
    "                self.dropped_out_qubit_ids.append(rand_id)\n",
    "            if rand_id != len(self.data_qubits):\n",
    "                self.delay_next_dropout_i = self.delay_next_dropout # reset delay if we're actually going to drop out!\n",
    "\n",
    "        for block in self.blocks:\n",
    "            # first apply the initial single qubit gates\n",
    "            for i in range(len(self.data_qubits)):\n",
    "                qubit = self.data_qubits[i]\n",
    "                symbol = sympy.Symbol('sym_l' + str(self.curr_layer_id) + '_q' + str(i))\n",
    "                #self.symbol_map[str(symbol)] = (False, weight)\n",
    "                self.circuit.append(gate(qubit)**symbol)\n",
    "\n",
    "            # according to the block num create the control gates\n",
    "\n",
    "            # add control gate version of the unitary gate if available (ie cz, cnot).\n",
    "            if gate == cirq.XX:\n",
    "                cgate = cirq.CNOT\n",
    "            elif gate == cirq.ZZ:\n",
    "                cgate = cirq.CZ\n",
    "            else:\n",
    "                cgate = cirq.CNOT\n",
    "            target = None\n",
    "            control = None\n",
    "            for i in range(len(self.data_qubits)):\n",
    "                if control is None:\n",
    "                    control_idx = i\n",
    "                    control = self.data_qubits[i]\n",
    "                # determine control\n",
    "                target_idx = (control_idx+len(self.data_qubits)-block)%len(self.data_qubits)\n",
    "                target = self.data_qubits[target_idx]\n",
    "                # add gate\n",
    "                symbol = sympy.Symbol('sym_l' + str(self.curr_layer_id) + '_q' + str(i)+ 'block'+str(block))\n",
    "                #self.symbol_map[str(symbol)] = (False, weight)\n",
    "                self.circuit.append(cgate(control,target)**symbol)\n",
    "                control = target\n",
    "                control_idx = target_idx\n",
    "        self.curr_layer_id += 1\n",
    "    \n",
    "    def get_builder_weights(self):\n",
    "        # returns symbol names in sorted order, which should match the order used for PQC (kinda hacky and can potentially break later)\n",
    "        # used as the next input for set_weights()\n",
    "        #\n",
    "        # Order of calls:\n",
    "        # tf.fit();\n",
    "        # builder.rebuild(tf.get_weights());\n",
    "        # add_layer()...;\n",
    "        # tf.set_weights(builder.get_builder_weights());\n",
    "        # tf.fit()\n",
    "        weights_list = []\n",
    "        \n",
    "        for k in sorted(self.symbol_map.keys()):\n",
    "            curr_is_dropout, curr_weight = self.symbol_map[k]\n",
    "            if not curr_is_dropout:\n",
    "                weights_list.append(curr_weight)\n",
    "        \n",
    "        return weights_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"2819.110312500001\" height=\"400.0\"><line x1=\"32.246796875\" x2=\"2789.110312500001\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"2789.110312500001\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"2789.110312500001\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"2789.110312500001\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"2789.110312500001\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"2789.110312500001\" y1=\"275.0\" y2=\"275.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"2789.110312500001\" y1=\"325.0\" y2=\"325.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"2789.110312500001\" y1=\"375.0\" y2=\"375.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"253.205234375\" x2=\"253.205234375\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"406.74005859375\" x2=\"406.74005859375\" y1=\"325.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"562.36298828125\" x2=\"562.36298828125\" y1=\"275.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"717.9859179687501\" x2=\"717.9859179687501\" y1=\"225.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"873.60884765625\" x2=\"873.60884765625\" y1=\"175.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1029.23177734375\" x2=\"1029.23177734375\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1184.85470703125\" x2=\"1184.85470703125\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1340.47763671875\" x2=\"1340.47763671875\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1607.8593359375\" x2=\"1607.8593359375\" y1=\"25.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1763.33009765625\" x2=\"1763.33009765625\" y1=\"125.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1918.800859375\" x2=\"1918.800859375\" y1=\"125.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2074.27162109375\" x2=\"2074.27162109375\" y1=\"225.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2231.8304882812504\" x2=\"2231.8304882812504\" y1=\"75.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2387.3012500000004\" x2=\"2387.3012500000004\" y1=\"75.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2542.7720117187505\" x2=\"2542.7720117187505\" y1=\"175.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2700.3308789062507\" x2=\"2700.3308789062507\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 1): </text><rect x=\"10.0\" y=\"205.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"255.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 1): </text><rect x=\"10.0\" y=\"305.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"10.0\" y=\"355.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"74.49359375\" y=\"5.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q0</text><rect x=\"74.49359375\" y=\"55.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q1</text><rect x=\"74.49359375\" y=\"105.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q2</text><rect x=\"74.49359375\" y=\"155.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q3</text><rect x=\"74.49359375\" y=\"205.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q4</text><rect x=\"74.49359375\" y=\"255.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q5</text><rect x=\"74.49359375\" y=\"305.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q6</text><rect x=\"74.49359375\" y=\"355.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q7</text><circle cx=\"253.205234375\" cy=\"25.0\" r=\"10.0\" /><rect x=\"187.481875\" y=\"355.0\" width=\"131.44671875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"253.205234375\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q0block1</text><rect x=\"338.92859375\" y=\"355.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"406.74005859375\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q1block1</text><rect x=\"338.92859375\" y=\"305.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"406.74005859375\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"494.55152343749995\" y=\"305.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"562.36298828125\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q2block1</text><rect x=\"494.55152343749995\" y=\"255.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"562.36298828125\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"494.55152343749995\" y=\"355.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"562.36298828125\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q7</text><rect x=\"650.1744531250001\" y=\"255.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"717.9859179687501\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q3block1</text><rect x=\"650.1744531250001\" y=\"205.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"717.9859179687501\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"650.1744531250001\" y=\"305.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"717.9859179687501\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q6</text><rect x=\"805.7973828125\" y=\"205.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"873.60884765625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q4block1</text><rect x=\"805.7973828125\" y=\"155.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"873.60884765625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"805.7973828125\" y=\"255.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"873.60884765625\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q5</text><rect x=\"961.4203125000001\" y=\"155.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1029.23177734375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q5block1</text><rect x=\"961.4203125000001\" y=\"105.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1029.23177734375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"961.4203125000001\" y=\"205.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1029.23177734375\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q4</text><rect x=\"1117.0432421875\" y=\"105.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1184.85470703125\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q6block1</text><rect x=\"1117.0432421875\" y=\"55.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1184.85470703125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1117.0432421875\" y=\"155.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1184.85470703125\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q3</text><rect x=\"1272.6661718750001\" y=\"55.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1340.47763671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q7block1</text><rect x=\"1272.6661718750001\" y=\"5.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1340.47763671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1272.6661718750001\" y=\"105.0\" width=\"135.6229296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1340.47763671875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q2</text><rect x=\"1428.2891015625\" y=\"5.0\" width=\"92.87890625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1474.7285546875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q0</text><rect x=\"1428.2891015625\" y=\"55.0\" width=\"92.87890625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1474.7285546875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q1</text><circle cx=\"1607.8593359375\" cy=\"25.0\" r=\"10.0\" /><rect x=\"1541.1680078125\" y=\"255.0\" width=\"133.38265625000003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1607.8593359375\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q0block3</text><rect x=\"1694.5506640625\" y=\"255.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1763.33009765625\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q1block3</text><rect x=\"1694.5506640625\" y=\"105.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1763.33009765625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1918.800859375\" cy=\"125.0\" r=\"10.0\" /><rect x=\"1852.1095312500001\" y=\"355.0\" width=\"133.38265625000003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1918.800859375\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q2block3</text><rect x=\"2005.4921875\" y=\"355.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2074.27162109375\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q3block3</text><rect x=\"2005.4921875\" y=\"205.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2074.27162109375\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"2163.0510546875003\" y=\"205.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2231.8304882812504\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q4block3</text><rect x=\"2163.0510546875003\" y=\"55.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2231.8304882812504\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"2387.3012500000004\" cy=\"75.0\" r=\"10.0\" /><rect x=\"2320.6099218750005\" y=\"305.0\" width=\"133.38265625000003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2387.3012500000004\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q5block3</text><rect x=\"2473.9925781250004\" y=\"305.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2542.7720117187505\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q6block3</text><rect x=\"2473.9925781250004\" y=\"155.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2542.7720117187505\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"2631.5514453125006\" y=\"155.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2700.3308789062507\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_l0_q7block3</text><rect x=\"2631.5514453125006\" y=\"5.0\" width=\"137.55886718750003\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2700.3308789062507\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7fad8f0b7f40>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = cirq.Circuit()\n",
    "demo_builder = CircuitLayerBuilder(circuit=circuit,\n",
    "                                   data_qubits = cirq.GridQubit.rect(4,2),\n",
    "                                   readout=cirq.GridQubit(-1,-1),blocks=[1,3])\n",
    "demo_builder.add_layer(gate=cirq.X)\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n",
      "15\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"2027.4167187500004\" height=\"400.0\"><line x1=\"32.246796875\" x2=\"1997.4167187500004\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"1997.4167187500004\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"1997.4167187500004\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"1997.4167187500004\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"1997.4167187500004\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"1997.4167187500004\" y1=\"275.0\" y2=\"275.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"1997.4167187500004\" y1=\"325.0\" y2=\"325.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"1997.4167187500004\" y1=\"375.0\" y2=\"375.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"236.27671875000001\" x2=\"236.27671875000001\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"355.95451171875004\" x2=\"355.95451171875004\" y1=\"325.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"477.7171289062501\" x2=\"477.7171289062501\" y1=\"275.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"599.5169335937501\" x2=\"599.5169335937501\" y1=\"225.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"721.2992382812502\" x2=\"721.2992382812502\" y1=\"175.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"843.0443554687502\" x2=\"843.0443554687502\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"843.0443554687502\" x2=\"843.0443554687502\" y1=\"275.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"964.7588476562502\" x2=\"964.7588476562502\" y1=\"75.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1085.5053710937502\" x2=\"1085.5053710937502\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1205.3353320312503\" x2=\"1205.3353320312503\" y1=\"125.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1323.9937500000003\" x2=\"1323.9937500000003\" y1=\"125.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1443.6201367187502\" x2=\"1443.6201367187502\" y1=\"225.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1565.3652539062505\" x2=\"1565.3652539062505\" y1=\"75.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1685.0594531250003\" x2=\"1685.0594531250003\" y1=\"75.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1804.7711523437504\" x2=\"1804.7711523437504\" y1=\"175.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1926.5337695312503\" x2=\"1926.5337695312503\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"55.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"105.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 1): </text><rect x=\"10.0\" y=\"205.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"255.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 1): </text><rect x=\"10.0\" y=\"305.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"10.0\" y=\"355.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"74.49359375\" y=\"5.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q0</text><rect x=\"74.49359375\" y=\"55.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q1</text><rect x=\"74.49359375\" y=\"105.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q2</text><rect x=\"74.49359375\" y=\"155.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q3</text><rect x=\"74.49359375\" y=\"205.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q4</text><rect x=\"74.49359375\" y=\"255.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q5</text><rect x=\"74.49359375\" y=\"305.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q6</text><rect x=\"74.49359375\" y=\"355.0\" width=\"92.98828125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"120.987734375\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_l0_q7</text><circle cx=\"236.27671875000001\" cy=\"25.0\" r=\"10.0\" /><rect x=\"187.481875\" y=\"355.0\" width=\"97.58968750000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"236.27671875000001\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_21_q7</text><rect x=\"305.0715625\" y=\"355.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"355.95451171875004\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_21_q7</text><rect x=\"305.0715625\" y=\"305.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"355.95451171875004\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"426.83746093750005\" y=\"305.0\" width=\"101.75933593750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"477.7171289062501\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_21_q6</text><rect x=\"426.83746093750005\" y=\"255.0\" width=\"101.75933593750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"477.7171289062501\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"426.83746093750005\" y=\"355.0\" width=\"101.75933593750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"477.7171289062501\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_31_q7</text><rect x=\"548.5967968750001\" y=\"255.0\" width=\"101.84027343750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.5169335937501\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_21_q5</text><rect x=\"548.5967968750001\" y=\"205.0\" width=\"101.84027343750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.5169335937501\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"548.5967968750001\" y=\"305.0\" width=\"101.84027343750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"599.5169335937501\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_31_q6</text><rect x=\"670.4370703125002\" y=\"205.0\" width=\"101.72433593750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"721.2992382812502\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_21_q4</text><rect x=\"670.4370703125002\" y=\"155.0\" width=\"101.72433593750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"721.2992382812502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"670.4370703125002\" y=\"255.0\" width=\"101.72433593750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"721.2992382812502\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_31_q5</text><rect x=\"792.1614062500001\" y=\"155.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"843.0443554687502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_21_q3</text><rect x=\"792.1614062500001\" y=\"105.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"843.0443554687502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"792.1614062500001\" y=\"205.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"843.0443554687502\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_31_q4</text><rect x=\"792.1614062500001\" y=\"355.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"843.0443554687502\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_41_q0</text><rect x=\"792.1614062500001\" y=\"255.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"843.0443554687502\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"913.9273046875002\" y=\"105.0\" width=\"101.66308593750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"964.7588476562502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_21_q2</text><rect x=\"913.9273046875002\" y=\"55.0\" width=\"101.66308593750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"964.7588476562502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"913.9273046875002\" y=\"155.0\" width=\"101.66308593750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"964.7588476562502\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_31_q3</text><rect x=\"1035.5903906250003\" y=\"55.0\" width=\"99.8299609375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1085.5053710937502\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_21_q1</text><rect x=\"1035.5903906250003\" y=\"5.0\" width=\"99.8299609375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1085.5053710937502\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1035.5903906250003\" y=\"105.0\" width=\"99.8299609375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1085.5053710937502\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_31_q2</text><rect x=\"1155.4203515625004\" y=\"5.0\" width=\"99.8299609375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1205.3353320312503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_31_q0</text><rect x=\"1155.4203515625004\" y=\"55.0\" width=\"99.8299609375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1205.3353320312503\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_31_q1</text><rect x=\"1155.4203515625004\" y=\"255.0\" width=\"99.8299609375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1205.3353320312503\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_41_q1</text><rect x=\"1155.4203515625004\" y=\"105.0\" width=\"99.8299609375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1205.3353320312503\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1323.9937500000003\" cy=\"125.0\" r=\"10.0\" /><rect x=\"1275.2503125000003\" y=\"355.0\" width=\"97.48687500000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1323.9937500000003\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_41_q2</text><rect x=\"1392.7371875000003\" y=\"355.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1443.6201367187502\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_41_q3</text><rect x=\"1392.7371875000003\" y=\"205.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1443.6201367187502\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1514.5030859375004\" y=\"205.0\" width=\"101.72433593750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1565.3652539062505\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_41_q4</text><rect x=\"1514.5030859375004\" y=\"55.0\" width=\"101.72433593750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1565.3652539062505\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><circle cx=\"1685.0594531250003\" cy=\"75.0\" r=\"10.0\" /><rect x=\"1636.2274218750003\" y=\"305.0\" width=\"97.66406250000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1685.0594531250003\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">X^sym_41_q5</text><rect x=\"1753.8914843750003\" y=\"305.0\" width=\"101.75933593750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1804.7711523437504\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_41_q6</text><rect x=\"1753.8914843750003\" y=\"155.0\" width=\"101.75933593750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1804.7711523437504\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"1875.6508203125004\" y=\"155.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1926.5337695312503\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">@^sym_41_q7</text><rect x=\"1875.6508203125004\" y=\"5.0\" width=\"101.76589843750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1926.5337695312503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f914bcc94f0>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "circuit = cirq.Circuit()\n",
    "qubits = cirq.GridQubit.rect(4, 2) #data_qubits\n",
    "\n",
    "#apply initial single qubit unitary gate\n",
    "\n",
    "for qubit in range(len(qubits)):\n",
    "    symbol = sympy.Symbol('sym_l' + str(0) + '_q' + str(qubit))      \n",
    "    # first apply a gate to all the channels\n",
    "    circuit.append(cirq.X(qubits[qubit])**(symbol))\n",
    "    # wrap around and entangle last qubit with first qubit\n",
    "# we have to apply a different for loop to match the structure\n",
    "print(len(qubits))\n",
    "for qubit in range(len(qubits)-1,0,-1):\n",
    "    symbol = sympy.Symbol('sym_2' + str(1) + '_q' + str(qubit))\n",
    "    if qubit == len(qubits)-1:\n",
    "        # apply first cycle of controlled gates\n",
    "        circuit.append(cirq.CNOT(qubits[0],qubits[qubit])**(symbol))\n",
    "        circuit.append(cirq.CNOT(qubits[qubit],qubits[qubit-1])**(symbol))\n",
    "    else:\n",
    "        circuit.append(cirq.CNOT(qubits[qubit],qubits[qubit-1])**(symbol))\n",
    "for qubit in range(len(qubits)):\n",
    "    symbol = sympy.Symbol('sym_3' + str(1) + '_q' + str(qubit))\n",
    "    # first apply a gate to all the channels\n",
    "    circuit.append(cirq.X(qubits[qubit])**(symbol))\n",
    "\n",
    "# need to generalize this\n",
    "\n",
    "symbol = sympy.Symbol('sym_4' + str(1) + '_q' + str(0))\n",
    "circuit.append(cirq.CNOT(qubits[qubit],qubits[5])**(symbol))\n",
    "symbol = sympy.Symbol('sym_4' + str(1) + '_q' + str(1))\n",
    "circuit.append(cirq.CNOT(qubits[5],qubits[2])**(symbol))\n",
    "symbol = sympy.Symbol('sym_4' + str(1) + '_q' + str(2))\n",
    "circuit.append(cirq.CNOT(qubits[2],qubits[7])**(symbol))\n",
    "symbol = sympy.Symbol('sym_4' + str(1) + '_q' + str(3))\n",
    "circuit.append(cirq.CNOT(qubits[7],qubits[4])**(symbol))\n",
    "symbol = sympy.Symbol('sym_4' + str(1) + '_q' + str(4))\n",
    "circuit.append(cirq.CNOT(qubits[4],qubits[1])**(symbol))\n",
    "symbol = sympy.Symbol('sym_4' + str(1) + '_q' + str(5))\n",
    "circuit.append(cirq.CNOT(qubits[1],qubits[6])**(symbol))\n",
    "symbol = sympy.Symbol('sym_4' + str(1) + '_q' + str(6))\n",
    "circuit.append(cirq.CNOT(qubits[6],qubits[3])**(symbol))\n",
    "symbol = sympy.Symbol('sym_4' + str(1) + '_q' + str(7))\n",
    "circuit.append(cirq.CNOT(qubits[3],qubits[0])**(symbol))\n",
    "\n",
    "# readout \n",
    "\n",
    "readout = cirq.Z(qubits[0])\n",
    "\n",
    "# Build the Keras model.\n",
    "#qlayer = tfq.layers.PQC(circuit, readout)\n",
    "print(len(qlayer.get_weights()[0]))\n",
    "model = tf.keras.Sequential([\n",
    "    # The input is the data-circuit, encoded as a tf.string\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
    "    qlayer,\n",
    "])\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CircuitLayerBuilder():\n",
    "    def __init__(self, circuit, data_qubits, readout, repeat_dropout=0, overlap_dropout=False):\n",
    "\n",
    "    self.data_qubits = data_qubits\n",
    "    self.readout = readout\n",
    "    self.curr_layer_id = 0\n",
    "    self.circuit = circuit\n",
    "    \n",
    "    def add_layer(self, gate, apply_dropout=False):\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sjo5hANFojhr"
   },
   "source": [
    "Build an example circuit layer to see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[cirq.GridQubit(0, 0), cirq.GridQubit(0, 1), cirq.GridQubit(1, 0), cirq.GridQubit(1, 1), cirq.GridQubit(2, 0), cirq.GridQubit(2, 1), cirq.GridQubit(3, 0), cirq.GridQubit(3, 1)]\n",
      "self.dropout_blacklist =\n",
      "[]\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"3989.0290625\" height=\"450.0\"><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"275.0\" y2=\"275.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"325.0\" y2=\"325.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"375.0\" y2=\"375.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"3959.0290625\" y1=\"425.0\" y2=\"425.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"134.9262109375\" x2=\"134.9262109375\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"256.19253906250003\" x2=\"256.19253906250003\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"377.42496093750003\" x2=\"377.42496093750003\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"499.6253515625\" x2=\"499.6253515625\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"621.8563671875\" x2=\"621.8563671875\" y1=\"25.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"744.1245703125\" x2=\"744.1245703125\" y1=\"25.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"866.4102734375001\" x2=\"866.4102734375001\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"988.6587890625001\" x2=\"988.6587890625001\" y1=\"25.0\" y2=\"425.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1109.997578125\" x2=\"1109.997578125\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1229.472890625\" x2=\"1229.472890625\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1348.914296875\" x2=\"1348.914296875\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1469.323671875\" x2=\"1469.323671875\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1589.763671875\" x2=\"1589.763671875\" y1=\"25.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1710.2408593750001\" x2=\"1710.2408593750001\" y1=\"25.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1830.7355468750002\" x2=\"1830.7355468750002\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1951.1930468750002\" x2=\"1951.1930468750002\" y1=\"25.0\" y2=\"425.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2072.5318359375005\" x2=\"2072.5318359375005\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2193.7981640625007\" x2=\"2193.7981640625007\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2315.0305859375003\" x2=\"2315.0305859375003\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2437.2309765625005\" x2=\"2437.2309765625005\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2559.4619921875005\" x2=\"2559.4619921875005\" y1=\"25.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2681.7301953125\" x2=\"2681.7301953125\" y1=\"25.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2804.0158984375003\" x2=\"2804.0158984375003\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2926.2644140625002\" x2=\"2926.2644140625002\" y1=\"25.0\" y2=\"425.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3047.603203125\" x2=\"3047.603203125\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3167.0785156250004\" x2=\"3167.0785156250004\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3286.519921875\" x2=\"3286.519921875\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3406.929296875\" x2=\"3406.929296875\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3527.369296875\" x2=\"3527.369296875\" y1=\"25.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3647.846484375\" x2=\"3647.846484375\" y1=\"25.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3768.341171875\" x2=\"3768.341171875\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3888.798671875\" x2=\"3888.798671875\" y1=\"25.0\" y2=\"425.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"105.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"155.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"205.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 1): </text><rect x=\"10.0\" y=\"255.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"305.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 1): </text><rect x=\"10.0\" y=\"355.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"10.0\" y=\"405.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"83.8178125\" y=\"55.0\" width=\"102.21679687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"134.9262109375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l0_q0</text><rect x=\"83.8178125\" y=\"5.0\" width=\"102.21679687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"134.9262109375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"206.03460937500003\" y=\"105.0\" width=\"100.315859375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"256.19253906250003\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l0_q1</text><rect x=\"206.03460937500003\" y=\"5.0\" width=\"100.315859375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"256.19253906250003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"326.35046875\" y=\"155.0\" width=\"102.14898437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"377.42496093750003\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l0_q2</text><rect x=\"326.35046875\" y=\"5.0\" width=\"102.14898437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"377.42496093750003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"448.499453125\" y=\"205.0\" width=\"102.25179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"499.6253515625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l0_q3</text><rect x=\"448.499453125\" y=\"5.0\" width=\"102.25179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"499.6253515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"570.75125\" y=\"255.0\" width=\"102.21023437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"621.8563671875\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l0_q4</text><rect x=\"570.75125\" y=\"5.0\" width=\"102.21023437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"621.8563671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"692.961484375\" y=\"305.0\" width=\"102.32617187500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"744.1245703125\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l0_q5</text><rect x=\"692.961484375\" y=\"5.0\" width=\"102.32617187500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"744.1245703125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"815.28765625\" y=\"355.0\" width=\"102.24523437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"866.4102734375001\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l0_q6</text><rect x=\"815.28765625\" y=\"5.0\" width=\"102.24523437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"866.4102734375001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"937.532890625\" y=\"405.0\" width=\"102.25179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"988.6587890625001\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l0_q7</text><rect x=\"937.532890625\" y=\"5.0\" width=\"102.25179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"988.6587890625001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1059.7846875\" y=\"55.0\" width=\"100.42578125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1109.997578125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l1_q0</text><rect x=\"1059.7846875\" y=\"5.0\" width=\"100.42578125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1109.997578125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1180.21046875\" y=\"105.0\" width=\"98.52484375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1229.472890625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l1_q1</text><rect x=\"1180.21046875\" y=\"5.0\" width=\"98.52484375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1229.472890625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1298.7353125\" y=\"155.0\" width=\"100.35796875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1348.914296875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l1_q2</text><rect x=\"1298.7353125\" y=\"5.0\" width=\"100.35796875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1348.914296875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1419.09328125\" y=\"205.0\" width=\"100.46078125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1469.323671875\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l1_q3</text><rect x=\"1419.09328125\" y=\"5.0\" width=\"100.46078125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1469.323671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1539.5540625\" y=\"255.0\" width=\"100.41921875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1589.763671875\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l1_q4</text><rect x=\"1539.5540625\" y=\"5.0\" width=\"100.41921875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1589.763671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1659.9732812500001\" y=\"305.0\" width=\"100.53515625000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1710.2408593750001\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l1_q5</text><rect x=\"1659.9732812500001\" y=\"5.0\" width=\"100.53515625000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1710.2408593750001\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1780.5084375000001\" y=\"355.0\" width=\"100.45421875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1830.7355468750002\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l1_q6</text><rect x=\"1780.5084375000001\" y=\"5.0\" width=\"100.45421875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1830.7355468750002\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1900.9626562500002\" y=\"405.0\" width=\"100.46078125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1951.1930468750002\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l1_q7</text><rect x=\"1900.9626562500002\" y=\"5.0\" width=\"100.46078125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1951.1930468750002\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2021.4234375000005\" y=\"55.0\" width=\"102.21679687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2072.5318359375005\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l2_q0</text><rect x=\"2021.4234375000005\" y=\"5.0\" width=\"102.21679687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2072.5318359375005\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"2143.6402343750005\" y=\"105.0\" width=\"100.315859375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2193.7981640625007\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l2_q1</text><rect x=\"2143.6402343750005\" y=\"5.0\" width=\"100.315859375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2193.7981640625007\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"2263.9560937500005\" y=\"155.0\" width=\"102.14898437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2315.0305859375003\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l2_q2</text><rect x=\"2263.9560937500005\" y=\"5.0\" width=\"102.14898437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2315.0305859375003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"2386.1050781250005\" y=\"205.0\" width=\"102.25179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2437.2309765625005\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l2_q3</text><rect x=\"2386.1050781250005\" y=\"5.0\" width=\"102.25179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2437.2309765625005\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"2508.3568750000004\" y=\"255.0\" width=\"102.21023437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2559.4619921875005\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l2_q4</text><rect x=\"2508.3568750000004\" y=\"5.0\" width=\"102.21023437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2559.4619921875005\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"2630.567109375\" y=\"305.0\" width=\"102.32617187500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2681.7301953125\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l2_q5</text><rect x=\"2630.567109375\" y=\"5.0\" width=\"102.32617187500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2681.7301953125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"2752.89328125\" y=\"355.0\" width=\"102.24523437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2804.0158984375003\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l2_q6</text><rect x=\"2752.89328125\" y=\"5.0\" width=\"102.24523437500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2804.0158984375003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"2875.1385156250003\" y=\"405.0\" width=\"102.25179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2926.2644140625002\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^sym_l2_q7</text><rect x=\"2875.1385156250003\" y=\"5.0\" width=\"102.25179687500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2926.2644140625002\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"2997.3903125\" y=\"55.0\" width=\"100.42578125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3047.603203125\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l3_q0</text><rect x=\"2997.3903125\" y=\"5.0\" width=\"100.42578125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3047.603203125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3117.81609375\" y=\"105.0\" width=\"98.52484375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3167.0785156250004\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l3_q1</text><rect x=\"3117.81609375\" y=\"5.0\" width=\"98.52484375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3167.0785156250004\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3236.3409375\" y=\"155.0\" width=\"100.35796875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3286.519921875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l3_q2</text><rect x=\"3236.3409375\" y=\"5.0\" width=\"100.35796875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3286.519921875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3356.69890625\" y=\"205.0\" width=\"100.46078125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3406.929296875\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l3_q3</text><rect x=\"3356.69890625\" y=\"5.0\" width=\"100.46078125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3406.929296875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3477.1596875\" y=\"255.0\" width=\"100.41921875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3527.369296875\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l3_q4</text><rect x=\"3477.1596875\" y=\"5.0\" width=\"100.41921875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3527.369296875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3597.57890625\" y=\"305.0\" width=\"100.53515625000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3647.846484375\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l3_q5</text><rect x=\"3597.57890625\" y=\"5.0\" width=\"100.53515625000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3647.846484375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3718.1140625\" y=\"355.0\" width=\"100.45421875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3768.341171875\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l3_q6</text><rect x=\"3718.1140625\" y=\"5.0\" width=\"100.45421875000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3768.341171875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3838.56828125\" y=\"405.0\" width=\"100.46078125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3888.798671875\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^sym_l3_q7</text><rect x=\"3838.56828125\" y=\"5.0\" width=\"100.46078125000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3888.798671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f91697aef10>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TEST CELL to make sure CircuitLayerBuilder works properly\n",
    "circuit = cirq.Circuit()\n",
    "demo_builder = CircuitLayerBuilder(circuit=circuit,\n",
    "                                   data_qubits = cirq.GridQubit.rect(4,2),\n",
    "                                   readout=cirq.GridQubit(-1,-1))\n",
    "\n",
    "demo_builder.add_layer(gate=cirq.XX)\n",
    "demo_builder.add_layer(gate=cirq.ZZ, apply_dropout=True)\n",
    "demo_builder.add_layer(gate=cirq.XX, apply_dropout=False)\n",
    "demo_builder.add_layer(gate=cirq.ZZ, apply_dropout=False)\n",
    "\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-QhPE1pojhu"
   },
   "source": [
    "Now build a two-layered model, matching the data-circuit size, and include the preparation and readout operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JiALbpwRGL69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_quantum_model(apply_dropout=False, n_dropout=5, builder=None, computed_weights_arr=None):\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    if builder is None or computed_weights_arr is None:\n",
    "        builder = CircuitLayerBuilder(\n",
    "            circuit=circuit,\n",
    "            data_qubits=data_qubits,\n",
    "            readout=readout,\n",
    "            repeat_dropout=n_dropout)\n",
    "    else:\n",
    "        builder.rebuild(circuit, data_qubits, readout, computed_weights_arr, preserve_dropout=apply_dropout)\n",
    "\n",
    "    # Then add layers (TODO: experiment by adding more).\n",
    "    builder.add_layer(cirq.XX, False)\n",
    "    builder.add_layer(cirq.ZZ, apply_dropout) # only drop out one qubit as per Schuld\n",
    "    builder.add_layer(cirq.XX, False)\n",
    "    builder.add_layer(cirq.ZZ, False)\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return builder, circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QZvVh7vojhx",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self.dropout_blacklist =\n",
      "[]\n",
      "Dropped out qubit id 11\n",
      "Dropped out qubit id 11\n",
      "Dropped out qubit id 11\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'SingleQubitPauliStringGateOperation' object has no attribute 'moments'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/IPython/core/formatters.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_real_method\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprint_method\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmethod\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/cirq/contrib/svg/svg.py\u001b[0m in \u001b[0;36m_repr_svg_\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    269\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_repr_svg_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;31m# coverage: ignore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 271\u001b[0;31m         \u001b[0m_validate_circuit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    272\u001b[0m         \u001b[0mtdd\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_text_diagram_drawer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    273\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtdd_to_svg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtdd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/cirq/contrib/svg/svg.py\u001b[0m in \u001b[0;36m_validate_circuit\u001b[0;34m(circuit)\u001b[0m\n\u001b[1;32m    247\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Can't draw SVG diagram for empty circuits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 249\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmom\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mmom\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcircuit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmoments\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    250\u001b[0m         raise ValueError(\n\u001b[1;32m    251\u001b[0m             \u001b[0;34m\"Can't draw SVG diagram for circuits with empty \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'SingleQubitPauliStringGateOperation' object has no attribute 'moments'"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f914aea94f0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_, model_circuit, model_readout = create_quantum_model(apply_dropout=True)\n",
    "SVGCircuit(model_readout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LY7vbY6yfABE"
   },
   "source": [
    "### 2.2 Wrap the model-circuit in a tfq-keras model\n",
    "\n",
    "Build the Keras model with the quantum components. This model is fed the \"quantum data\", from `x_train_circ`, that encodes the classical data. It uses a *Parametrized Quantum Circuit* layer, `tfq.layers.PQC`, to train the model circuit, on the quantum data.\n",
    "\n",
    "To classify these images, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed taking the expectation of a readout qubit in a parameterized circuit. The expectation returns a value between 1 and -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYdf_KOxojh0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "<tensorflow_quantum.python.layers.high_level.pqc.PQC object at 0x7f914ae93040>\n"
     ]
    }
   ],
   "source": [
    "# Build the Keras model.\n",
    "qlayer = tfq.layers.PQC(model_circuit, model_readout)\n",
    "print(len(qlayer.get_weights()[0]))\n",
    "model = tf.keras.Sequential([\n",
    "    # The input is the data-circuit, encoded as a tf.string\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
    "    qlayer,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jz-FbVc9ojh3"
   },
   "source": [
    "Next, describe the training procedure to the model, using the `compile` method.\n",
    "\n",
    "Since the the expected readout is in the range `[-1,1]`, optimizing the hinge loss is a somewhat natural fit. \n",
    "\n",
    "Note: Another valid approach would be to shift the output range to `[0,1]`, and treat it as the probability the model assigns to class `3`. This could be used with a standard a `tf.losses.BinaryCrossentropy` loss.\n",
    "\n",
    "To use the hinge loss here you need to make two small adjustments. First convert the labels, `y_train_nocon`, from boolean to `[-1,1]`, as expected by the hinge loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgMNkC1Fojh5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_hinge = 2.0*y_train_nocon-1.0\n",
    "y_test_hinge = 2.0*y_test-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nwnveDiojh7"
   },
   "source": [
    "Second, use a custiom `hinge_accuracy` metric that correctly handles `[-1, 1]` as the `y_true` labels argument. \n",
    "`tf.losses.BinaryAccuracy(threshold=0.0)` expects `y_true` to be a boolean, and so can't be used with hinge loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XKtZ_TEojh8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hinge_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true) > 0.0\n",
    "    y_pred = tf.squeeze(y_pred) > 0.0\n",
    "    result = tf.cast(y_true == y_pred, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlpETlLRojiA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.Hinge(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[hinge_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jkHq2RstojiC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pqc_2 (PQC)                  (None, 1)                 15        \n",
      "=================================================================\n",
      "Total params: 15\n",
      "Trainable params: 15\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"tb_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsuOzDYblA9s"
   },
   "source": [
    "### Train the quantum model\n",
    "\n",
    "Now train the model—this takes about 45 min. If you don't want to wait that long, use a small subset of the data (set `NUM_EXAMPLES=500`, below). This doesn't really affect the model's progress during training (it only has 32 parameters, and doesn't need much data to constrain these). Using fewer examples just ends training earlier (5min), but runs long enough to show that it is making progress in the validation logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8vuQpSLlBV2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 20\n",
    "DROPOUT_EPOCHS = 2 # keep qubits dropped out for this num of epochs\n",
    "BATCH_SIZE = 32\n",
    "NUM_EXAMPLES = len(x_train_tfcirc)\n",
    "#NUM_EXAMPLES=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJnNG-3JojiI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
    "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer PQC has arguments in `__init__` and therefore must override `get_config`.\n",
      "Epoch 1/20\n",
      "324/324 [==============================] - 17s 52ms/step - loss: 1.0023 - hinge_accuracy: 0.4996 - val_loss: 0.7915 - val_hinge_accuracy: 0.6356\n",
      "Epoch 2/20\n",
      "324/324 [==============================] - 14s 43ms/step - loss: 1.0027 - hinge_accuracy: 0.4982 - val_loss: 0.7798 - val_hinge_accuracy: 0.6356\n",
      "Epoch 3/20\n",
      "324/324 [==============================] - 14s 42ms/step - loss: 1.0087 - hinge_accuracy: 0.4943 - val_loss: 0.7626 - val_hinge_accuracy: 0.6356\n",
      "Epoch 4/20\n",
      "324/324 [==============================] - 14s 42ms/step - loss: 1.0055 - hinge_accuracy: 0.4967 - val_loss: 0.7425 - val_hinge_accuracy: 0.6356\n",
      "Epoch 5/20\n",
      "324/324 [==============================] - 14s 44ms/step - loss: 0.9955 - hinge_accuracy: 0.4974 - val_loss: 0.7359 - val_hinge_accuracy: 0.6321\n",
      "Epoch 6/20\n",
      "324/324 [==============================] - 14s 43ms/step - loss: 1.0007 - hinge_accuracy: 0.4986 - val_loss: 0.7181 - val_hinge_accuracy: 0.6321\n",
      "Epoch 7/20\n",
      "324/324 [==============================] - 15s 46ms/step - loss: 1.0060 - hinge_accuracy: 0.4947 - val_loss: 0.7085 - val_hinge_accuracy: 0.7268\n",
      "Epoch 8/20\n",
      "324/324 [==============================] - 14s 42ms/step - loss: 0.9982 - hinge_accuracy: 0.4983 - val_loss: 0.6950 - val_hinge_accuracy: 0.7268\n",
      "Epoch 9/20\n",
      "324/324 [==============================] - 14s 43ms/step - loss: 0.9975 - hinge_accuracy: 0.5031 - val_loss: 0.6792 - val_hinge_accuracy: 0.7268\n",
      "Epoch 10/20\n",
      "324/324 [==============================] - 14s 42ms/step - loss: 1.0005 - hinge_accuracy: 0.5032 - val_loss: 0.6659 - val_hinge_accuracy: 0.7268\n",
      "Epoch 11/20\n",
      "324/324 [==============================] - 14s 42ms/step - loss: 0.9954 - hinge_accuracy: 0.5040 - val_loss: 0.6573 - val_hinge_accuracy: 0.7268\n",
      "Epoch 12/20\n",
      "324/324 [==============================] - 14s 42ms/step - loss: 0.9971 - hinge_accuracy: 0.5048 - val_loss: 0.6513 - val_hinge_accuracy: 0.7268\n",
      "Epoch 13/20\n",
      "324/324 [==============================] - 14s 42ms/step - loss: 1.0011 - hinge_accuracy: 0.5027 - val_loss: 0.6464 - val_hinge_accuracy: 0.7268\n",
      "Epoch 14/20\n",
      "324/324 [==============================] - 14s 43ms/step - loss: 0.9920 - hinge_accuracy: 0.5070 - val_loss: 0.6332 - val_hinge_accuracy: 0.7268\n",
      "Epoch 15/20\n",
      "324/324 [==============================] - 15s 46ms/step - loss: 0.9963 - hinge_accuracy: 0.5024 - val_loss: 0.6260 - val_hinge_accuracy: 0.7268\n",
      "Epoch 16/20\n",
      "324/324 [==============================] - 15s 46ms/step - loss: 0.9945 - hinge_accuracy: 0.5044 - val_loss: 0.6203 - val_hinge_accuracy: 0.7268\n",
      "Epoch 17/20\n",
      "324/324 [==============================] - 16s 50ms/step - loss: 0.9995 - hinge_accuracy: 0.5014 - val_loss: 0.6167 - val_hinge_accuracy: 0.7268\n",
      "Epoch 18/20\n",
      "324/324 [==============================] - 15s 47ms/step - loss: 0.9966 - hinge_accuracy: 0.5019 - val_loss: 0.6163 - val_hinge_accuracy: 0.7268\n",
      "Epoch 19/20\n",
      "324/324 [==============================] - 15s 46ms/step - loss: 1.0008 - hinge_accuracy: 0.5016 - val_loss: 0.6141 - val_hinge_accuracy: 0.7268\n",
      "Epoch 20/20\n",
      "324/324 [==============================] - 16s 48ms/step - loss: 1.0046 - hinge_accuracy: 0.4976 - val_loss: 0.6069 - val_hinge_accuracy: 0.7268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f912cda5a30>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "  x_train_tfcirc_sub, y_train_hinge_sub,\n",
    "  batch_size=32,\n",
    "  epochs=EPOCHS,\n",
    "  verbose=1,\n",
    "  validation_data=(x_test_tfcirc, y_test_hinge),\n",
    "  callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMSdgGC1GL7D"
   },
   "source": [
    "Training this model to convergence should achieve >85% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(apply_dropout=False):\n",
    "    for i in range(EPOCHS):        \n",
    "        # HACK - build new quantum circuit for each epoch and copy over the weights from the old one\n",
    "        if i == EPOCHS-1:\n",
    "            # Never use dropout on the last epoch; we can't get sane results otherwise\n",
    "            apply_dropout = False\n",
    "        \n",
    "        if i == 0:\n",
    "            model_builder, model_circuit, model_readout = create_quantum_model(apply_dropout, DROPOUT_EPOCHS)\n",
    "            qlayer = tfq.layers.PQC(model_circuit, model_readout)\n",
    "        else:\n",
    "            model_builder, model_circuit, model_readout = create_quantum_model(apply_dropout, -1, model_builder, qlayer.get_weights()[0])\n",
    "            qlayer_new = tfq.layers.PQC(model_circuit, model_readout,\n",
    "                                        initializer=tf.keras.initializers.Zeros)\n",
    "            curr_l = model_builder.get_builder_weights()\n",
    "            qlayer_new.set_weights([np.array(curr_l, dtype=np.float32)])\n",
    "            qlayer = qlayer_new\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "            qlayer,\n",
    "        ])\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.Hinge(),\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            metrics=[hinge_accuracy])\n",
    "\n",
    "        # Now fit the model for this epoch\n",
    "        model.fit(\n",
    "              x_train_tfcirc_sub, y_train_hinge_sub,\n",
    "              batch_size=32,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test_tfcirc, y_test_hinge),\n",
    "              callbacks=[tensorboard_callback])\n",
    "    print(model.loss())\n",
    "    tf.summary.scalar('loss', train_loss.result(), step=i)\n",
    "    tf.summary.scalar('accuracy', train_accuracy.result(), step=i)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer PQC has arguments in `__init__` and therefore must override `get_config`.\n",
      "16/16 [==============================] - 42s 3s/step - loss: 1.0024 - hinge_accuracy: 0.4368 - val_loss: 1.0040 - val_hinge_accuracy: 0.4451\n",
      "self.dropped_out_qubit_ids = \n",
      "[]\n",
      "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... Layer PQC has arguments in `__init__` and therefore must override `get_config`.\n",
      " 2/16 [==>...........................] - ETA: 19s - loss: 0.9966 - hinge_accuracy: 0.5547"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-ddb72d14d730>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-41-e3331614fe77>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(apply_dropout)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0;31m# Now fit the model for this epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         model.fit(\n\u001b[0m\u001b[1;32m     30\u001b[0m               \u001b[0mx_train_tfcirc_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_hinge_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = train_model(apply_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Non-dropout training set perf:\")\n",
    "model.evaluate(x_train_tfcirc_sub, y_train_hinge_sub)\n",
    "print(\"Non-dropout test set perf:\")\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya9qP3KkojiM",
    "tags": []
   },
   "outputs": [],
   "source": [
    "dropout_model = train_model(apply_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dropout training set perf:\")\n",
    "dropout_model.evaluate(x_train_tfcirc_sub, y_train_hinge_sub)\n",
    "print(\"Dropout test set perf:\")\n",
    "qnn_results = dropout_model.evaluate(x_test_tfcirc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ER7B7aaojiP"
   },
   "source": [
    "Note: The training accuracy reports the average over the epoch. The validation accuracy is evaluated at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8952YvuWGL7J"
   },
   "source": [
    "## 4. Classical neural network\n",
    "\n",
    "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
    "\n",
    "In the following example, a classical neural network is used for for the 3-6 classification problem using the entire 28x28 image instead of subsampling the image. This easily converges to nearly 100% accuracy of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZofEHhLGL7L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiAJl7sZojiU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5-5BVJaojiZ"
   },
   "source": [
    "The above model has nearly 1.2M parameters. For a more fair comparison, try a 37-parameter model, on the subsampled images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70TOM6r-ojiZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fair_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_fair_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lA_Fx-8gojid",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x_train_bin,\n",
    "          y_train_nocon,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "fair_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH3mam7EGL7N"
   },
   "source": [
    "## 5. Comparison\n",
    "\n",
    "Higher resolution input and a more powerful model make this problem easy for the CNN. While a classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOMeN7pMGL7P",
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnn_accuracy = qnn_results[1]\n",
    "cnn_accuracy = cnn_results[1]\n",
    "fair_nn_accuracy = fair_nn_results[1]\n",
    "\n",
    "sns.barplot([\"Quantum\", \"Classical, full\", \"Classical, fair\"],\n",
    "            [qnn_accuracy, cnn_accuracy, fair_nn_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
