{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLOXFOT5Q40E"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "id": "iiQkM5ZgQ8r2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6331ZSsQGY3"
   },
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9Jcnb8bQQyd"
   },
   "source": [
    "Based on https://www.tensorflow.org/quantum/tutorials/mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udLObUVeGfTs"
   },
   "source": [
    "We build a quantum neural network (QNN) to classify a simplified version of MNIST, similar to the approach used in <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a>. The performance of the quantum neural network on this classical data problem is compared with a classical neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X35qHdh5Gzqg"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TorxE5tnkvb2",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tfq-nightly 0.5.0.dev20210516 requires grpcio==1.30.0, but you have grpcio 1.32.0 which is incompatible.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -q tensorflow==2.3.1\n",
    "!python3.8 -m pip install -q tensorflow==2.4.1\n",
    "!python3.8 -m pip install tensorboard_plugin_profile==2.3.0\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxkQA6oblNqI"
   },
   "source": [
    "Install TensorFlow Quantum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "saFHsRDpkvkH",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tfq-nightly in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (0.5.0.dev20210516)\n",
      "Collecting grpcio==1.30.0\n",
      "  Using cached grpcio-1.30.0-cp38-cp38-macosx_10_9_x86_64.whl (2.8 MB)\n",
      "Requirement already satisfied: google-api-core==1.21.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (1.21.0)\n",
      "Requirement already satisfied: sympy==1.5 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (1.5)\n",
      "Requirement already satisfied: cirq==0.11.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: googleapis-common-protos==1.52.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (1.52.0)\n",
      "Requirement already satisfied: google-auth==1.18.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (1.18.0)\n",
      "Requirement already satisfied: protobuf==3.13.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from tfq-nightly) (3.13.0)\n",
      "Requirement already satisfied: cirq-core==0.11.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq==0.11.0->tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: cirq-google==0.11.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq==0.11.0->tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: networkx~=2.4 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.5.1)\n",
      "Requirement already satisfied: tqdm in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.59.0)\n",
      "Requirement already satisfied: matplotlib~=3.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (3.3.4)\n",
      "Requirement already satisfied: pandas in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.2.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (3.7.4.3)\n",
      "Requirement already satisfied: sortedcontainers~=2.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.3.0)\n",
      "Requirement already satisfied: scipy in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.6.2)\n",
      "Requirement already satisfied: numpy~=1.16 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.19.2)\n",
      "Requirement already satisfied: requests~=2.18 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.25.1)\n",
      "Requirement already satisfied: pytz in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (2021.1)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (52.0.0.post20210125)\n",
      "Requirement already satisfied: six>=1.10.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (4.2.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (0.2.8)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (4.7.2)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from sympy==1.5->tfq-nightly) (1.2.1)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (0.10.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.3 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.8.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from networkx~=2.4->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.4.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth==1.18.0->tfq-nightly) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in /Users/rickyyoung/opt/anaconda3/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.0.0)\n",
      "Installing collected packages: grpcio\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires grpcio~=1.32.0, but you have grpcio 1.30.0 which is incompatible.\u001b[0m\n",
      "Successfully installed grpcio-1.30.0\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -q tensorflow-quantum\n",
    "!python3.8 -m pip install tfq-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdgMMZEBGqyl"
   },
   "source": [
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "enZ300Bflq80",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b08Mmbs8lr81"
   },
   "source": [
    "## 1. Load the data\n",
    "\n",
    "In this tutorial you will build a binary classifier to distinguish between the digits 3 and 6, following <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> This section covers the data handling that:\n",
    "\n",
    "- Loads the raw data from Keras.\n",
    "- Filters the dataset to only 3s and 6s.\n",
    "- Downscales the images so they fit can fit in a quantum computer.\n",
    "- Removes any contradictory examples.\n",
    "- Converts the binary images to Cirq circuits.\n",
    "- Converts the Cirq circuits to TensorFlow Quantum circuits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDUdGxn-ojgy"
   },
   "source": [
    "### 1.1 Load the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZyGXlaKojgz"
   },
   "source": [
    "Load the MNIST dataset distributed with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d9OSExvCojg0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original training examples: 60000\n",
      "Number of original test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZpbygdGojg3"
   },
   "source": [
    "Filter the dataset to keep just the 3s and 6s,  remove the other classes. At the same time convert the label, `y`, to boolean: `True` for `3` and `False` for 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hOw68cCZojg4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def filter_36(x, y):\n",
    "    keep = (y == 3) | (y == 6)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == 3\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "p-XEU8egGL6q",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered training examples: 12049\n",
      "Number of filtered test examples: 1968\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = filter_36(x_train, y_train)\n",
    "x_test, y_test = filter_36(x_test, y_test)\n",
    "\n",
    "print(\"Number of filtered training examples:\", len(x_train))\n",
    "print(\"Number of filtered test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wyiaP0Xojg_"
   },
   "source": [
    "Show the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "j5STP7MbojhA",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f918d1bcc70>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train[0, :, :, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNS9sVPQojhC"
   },
   "source": [
    "### 1.2 Downscale the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmmtplIFGL6t"
   },
   "source": [
    "An image size of 28x28 is much too large for current quantum computers. Resize the image down to 4x4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbhUdBFWojhE",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
    "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOMd7zIjGL6x"
   },
   "source": [
    "Again, display the first training example—after resize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YIYOtCRIGL6y",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7f916b30e2e0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGeF1_qtojhK"
   },
   "source": [
    "### 1.3 Remove contradictory examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZLkq2yeojhL"
   },
   "source": [
    "From section *3.3 Learning to Distinguish Digits* of <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a>, filter the dataset to remove images that are labeled as belonging to both classes.\n",
    "\n",
    "This is not a standard machine-learning procedure, but is included in the interest of following the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LqOPW0C7ojhL",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def remove_contradicting(xs, ys):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    orig_x = {}\n",
    "    # Determine the set of labels for each unique image:\n",
    "    for x,y in zip(xs,ys):\n",
    "       orig_x[tuple(x.flatten())] = x\n",
    "       mapping[tuple(x.flatten())].add(y)\n",
    "    \n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    for flatten_x in mapping:\n",
    "      x = orig_x[flatten_x]\n",
    "      labels = mapping[flatten_x]\n",
    "      if len(labels) == 1:\n",
    "          new_x.append(x)\n",
    "          new_y.append(next(iter(labels)))\n",
    "      else:\n",
    "          # Throw out images that match more than one label.\n",
    "          pass\n",
    "    \n",
    "    num_uniq_3 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
    "    num_uniq_6 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
    "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
    "\n",
    "    print(\"Number of unique images:\", len(mapping.values()))\n",
    "    print(\"Number of unique 3s: \", num_uniq_3)\n",
    "    print(\"Number of unique 6s: \", num_uniq_6)\n",
    "    print(\"Number of unique contradicting labels (both 3 and 6): \", num_uniq_both)\n",
    "    print()\n",
    "    print(\"Initial number of images: \", len(xs))\n",
    "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
    "    \n",
    "    return np.array(new_x), np.array(new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMOiJfz_ojhP"
   },
   "source": [
    "The resulting counts do not closely match the reported values, but the exact procedure is not specified.\n",
    "\n",
    "It is also worth noting here that applying filtering contradictory examples at this point does not totally prevent the model from receiving contradictory training examples: the next step binarizes the data which will cause more collisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "zpnsAssWojhP",
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 10387\n",
      "Number of unique 3s:  4912\n",
      "Number of unique 6s:  5426\n",
      "Number of unique contradicting labels (both 3 and 6):  49\n",
      "\n",
      "Initial number of images:  12049\n",
      "Remaining non-contradicting unique images:  10338\n"
     ]
    }
   ],
   "source": [
    "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ5NVaPojhT"
   },
   "source": [
    "### 1.4 Encode the data as quantum circuits\n",
    "\n",
    "To process images using a quantum computer, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed representing each pixel with a qubit, with the state depending on the value of the pixel. The first step is to convert to a binary encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1z8J7OyDojhV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
    "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ5NVaPojhU"
   },
   "source": [
    "If you were to remove contradictory images at this point you would be left with only 193, likely not enough for effective training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1z8J7OyDojhW",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 193\n",
      "Number of unique 3s:  80\n",
      "Number of unique 6s:  69\n",
      "Number of unique contradicting labels (both 3 and 6):  44\n",
      "\n",
      "Initial number of images:  10338\n",
      "Remaining non-contradicting unique images:  149\n"
     ]
    }
   ],
   "source": [
    "_ = remove_contradicting(x_train_bin, y_train_nocon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLyxS9KlojhZ"
   },
   "source": [
    "The qubits at pixel indices with values that exceed a threshold, are rotated through an $X$ gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aOu_3-3ZGL61",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def convert_to_circuit(image):\n",
    "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
    "    values = np.ndarray.flatten(image)\n",
    "    qubits = cirq.GridQubit.rect(4, 4)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(values):\n",
    "        if value:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "    return circuit\n",
    "\n",
    "\n",
    "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
    "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSCXqzOzojhd"
   },
   "source": [
    "Here is the circuit created for the first example (circuit diagrams do not show qubits with zero gates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "w3POmUEUojhe",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"164.49359375\" height=\"100.0\"><line x1=\"32.246796875\" x2=\"134.49359375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"32.246796875\" x2=\"134.49359375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"55.0\" width=\"44.49359375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"32.246796875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"74.49359375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"94.49359375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"74.49359375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"94.49359375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f916b236cd0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(x_train_circ[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEQMxCcBojhg"
   },
   "source": [
    "Compare this circuit to the indices where the image value exceeds the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "TBIsiXdtojhh",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [3, 1]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_img = x_train_bin[0,:,:,0]\n",
    "indices = np.array(np.where(bin_img)).T\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWZ24w1Oojhk"
   },
   "source": [
    "Convert these `Cirq` circuits to tensors for `tfq`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "IZStEMk4ojhk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
    "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4USiqeOqGL67"
   },
   "source": [
    "## 2. Quantum neural network\n",
    "\n",
    "There is little guidance for a quantum circuit structure that classifies images. Since the classification is based on the expectation of the readout qubit, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose using two qubit gates, with the readout qubit always acted upon. This is similar in some ways to running small a <a href=\"https://arxiv.org/abs/1511.06464\" class=\"external\">Unitary RNN</a> across the pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knIzawEeojho"
   },
   "source": [
    "### 2.1 Build the model circuit\n",
    "\n",
    "This following example shows this layered approach. Each layer uses *n* instances of the same gate, with each of the data qubits acting on the readout qubit.\n",
    "\n",
    "Start with a simple class that will add a layer of these gates to a circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-hjxxgU5ojho",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([cirq.X, cirq.XX, cirq.Y, cirq.YY, cirq.Z, cirq.ZZ, cirq.H, cirq.CZ, cirq.CNOT, cirq.SWAP, cirq.ISWAP, cirq.PhasedXPowGate(phase_exponent=0.123), cirq.PhasedISwapPowGate(phase_exponent=0.123), cirq.FSimGate(theta=0.123, phi=0.456), cirq.I])\n",
      "dict_keys([cirq.depolarize(p=0.01), cirq.asymmetric_depolarize(error_probabilities={'I': 0.94, 'X': 0.01, 'Y': 0.02, 'Z': 0.03}), cirq.generalized_amplitude_damp(p=0.01,gamma=0.02), cirq.amplitude_damp(gamma=0.01), cirq.ResetChannel(), cirq.phase_damp(gamma=0.01), cirq.phase_flip(p=0.01), cirq.bit_flip(p=0.01)])\n"
     ]
    }
   ],
   "source": [
    "print(tfq.util.get_supported_gates().keys())\n",
    "print(tfq.util.get_supported_channels().keys())\n",
    "\n",
    "class CircuitLayerBuilder():\n",
    "    def __init__(self, data_qubits, readout, dropout_aux_qubits=[]):\n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "        self.curr_layer_id = 0\n",
    "        self.dropout_aux_qubits = dropout_aux_qubits\n",
    "    \n",
    "    def add_layer(self, circuit, gate, prefix):\n",
    "        dropout_id = np.random.randint(0, len(self.data_qubits) + 1)\n",
    "        for i in range(len(self.data_qubits)):\n",
    "            qubit = self.data_qubits[i]\n",
    "            symbol = sympy.Symbol(prefix + '_' + str(i))\n",
    "            circuit.append(gate(qubit, self.readout)**symbol)\n",
    "        if self.curr_layer_id >= len(self.dropout_aux_qubits):\n",
    "            # It is expected that len(self.dropout_aux_qubits) == num_layers-1. This is because\n",
    "            # Dropout essentially changes the input of the next layer, so we only have enough aux qubits for n-1 layers.\n",
    "            # Also, this if helps us avoid the qubit-switching logic if we don't actually have dropout.\n",
    "            return\n",
    "        # switch qubit with the right zero-qubit\n",
    "        if dropout_id < len(self.data_qubits):\n",
    "            tmp = self.data_qubits[dropout_id]\n",
    "            self.data_qubits[dropout_id] = self.dropout_aux_qubits[self.curr_layer_id]\n",
    "            self.dropout_aux_qubits[self.curr_layer_id] = tmp\n",
    "        self.curr_layer_id += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sjo5hANFojhr"
   },
   "source": [
    "Build an example circuit layer to see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "SzXWOpUGojhs",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"1437.1296875000003\" height=\"400.0\"><line x1=\"36.90890625\" x2=\"1407.1296875000003\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"1407.1296875000003\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"1407.1296875000003\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"1407.1296875000003\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"1407.1296875000003\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"1407.1296875000003\" y1=\"275.0\" y2=\"275.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"1407.1296875000003\" y1=\"325.0\" y2=\"325.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"1407.1296875000003\" y1=\"375.0\" y2=\"375.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"115.86078125\" x2=\"115.86078125\" y1=\"175.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"198.99625\" x2=\"198.99625\" y1=\"175.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"282.09781250000003\" x2=\"282.09781250000003\" y1=\"175.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"366.16734375\" x2=\"366.16734375\" y1=\"175.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"449.3752734375\" x2=\"449.3752734375\" y1=\"125.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"530.7197265625\" x2=\"530.7197265625\" y1=\"175.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"612.0302734375\" x2=\"612.0302734375\" y1=\"175.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"694.3087890625001\" x2=\"694.3087890625001\" y1=\"175.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"777.51671875\" x2=\"777.51671875\" y1=\"75.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"860.6521875\" x2=\"860.6521875\" y1=\"175.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"943.7537500000001\" x2=\"943.7537500000001\" y1=\"175.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1027.82328125\" x2=\"1027.82328125\" y1=\"175.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1111.0312109375002\" x2=\"1111.0312109375002\" y1=\"75.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1192.3756640625002\" x2=\"1192.3756640625002\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1273.6862109375002\" x2=\"1273.6862109375002\" y1=\"175.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1355.9647265625001\" x2=\"1355.9647265625001\" y1=\"175.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-4, -4): </text><rect x=\"10.0\" y=\"55.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-3, -3): </text><rect x=\"10.0\" y=\"105.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-2, -2): </text><rect x=\"10.0\" y=\"155.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"205.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"255.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"305.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"355.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"83.8178125\" y=\"205.0\" width=\"64.0859375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"115.86078125\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_0</text><rect x=\"83.8178125\" y=\"155.0\" width=\"64.0859375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"115.86078125\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"167.90375\" y=\"255.0\" width=\"62.185\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"198.99625\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_1</text><rect x=\"167.90375\" y=\"155.0\" width=\"62.185\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"198.99625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"250.08875000000003\" y=\"305.0\" width=\"64.018125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"282.09781250000003\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_2</text><rect x=\"250.08875000000003\" y=\"155.0\" width=\"64.018125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"282.09781250000003\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"334.106875\" y=\"355.0\" width=\"64.1209375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"366.16734375\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_3</text><rect x=\"334.106875\" y=\"155.0\" width=\"64.1209375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"366.16734375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"418.2278125\" y=\"105.0\" width=\"62.294921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"449.3752734375\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"418.2278125\" y=\"155.0\" width=\"62.294921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"449.3752734375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz_0</text><rect x=\"500.522734375\" y=\"255.0\" width=\"60.393984375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"530.7197265625\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz_1</text><rect x=\"500.522734375\" y=\"155.0\" width=\"60.393984375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"530.7197265625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"580.91671875\" y=\"305.0\" width=\"62.227109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"612.0302734375\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz_2</text><rect x=\"580.91671875\" y=\"155.0\" width=\"62.227109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"612.0302734375\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"663.143828125\" y=\"355.0\" width=\"62.329921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"694.3087890625001\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz_3</text><rect x=\"663.143828125\" y=\"155.0\" width=\"62.329921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"694.3087890625001\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"745.47375\" y=\"55.0\" width=\"64.0859375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"777.51671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"745.47375\" y=\"155.0\" width=\"64.0859375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"777.51671875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_0</text><rect x=\"829.5596875\" y=\"255.0\" width=\"62.185\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"860.6521875\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_1</text><rect x=\"829.5596875\" y=\"155.0\" width=\"62.185\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"860.6521875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"911.7446875\" y=\"305.0\" width=\"64.018125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"943.7537500000001\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_2</text><rect x=\"911.7446875\" y=\"155.0\" width=\"64.018125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"943.7537500000001\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"995.7628125\" y=\"355.0\" width=\"64.1209375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1027.82328125\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_3</text><rect x=\"995.7628125\" y=\"155.0\" width=\"64.1209375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1027.82328125\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1079.8837500000002\" y=\"55.0\" width=\"62.294921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1111.0312109375002\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1079.8837500000002\" y=\"155.0\" width=\"62.294921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1111.0312109375002\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz_0</text><rect x=\"1162.1786718750002\" y=\"5.0\" width=\"60.393984375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1192.3756640625002\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1162.1786718750002\" y=\"155.0\" width=\"60.393984375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1192.3756640625002\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz_1</text><rect x=\"1242.5726562500001\" y=\"305.0\" width=\"62.227109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1273.6862109375002\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz_2</text><rect x=\"1242.5726562500001\" y=\"155.0\" width=\"62.227109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1273.6862109375002\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1324.7997656250002\" y=\"355.0\" width=\"62.329921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1355.9647265625001\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz_3</text><rect x=\"1324.7997656250002\" y=\"155.0\" width=\"62.329921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1355.9647265625001\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f916d19dd60>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aux1 = cirq.GridQubit(-2, -2)\n",
    "aux2 = cirq.GridQubit(-3, -3)\n",
    "aux3 = cirq.GridQubit(-4, -4)\n",
    "aux_qubits = [aux1, aux2, aux3]\n",
    "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
    "                                   readout=cirq.GridQubit(-1,-1),\n",
    "                                   dropout_aux_qubits=aux_qubits)\n",
    "\n",
    "circuit = cirq.Circuit()\n",
    "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
    "demo_builder.add_layer(circuit, gate = cirq.ZZ, prefix='zz')\n",
    "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
    "demo_builder.add_layer(circuit, gate = cirq.ZZ, prefix='zz')\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-QhPE1pojhu"
   },
   "source": [
    "Now build a two-layered model, matching the data-circuit size, and include the preparation and readout operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "JiALbpwRGL69",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_quantum_model(apply_dropout=False):\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    if apply_dropout:\n",
    "        aux1 = cirq.GridQubit(0, -1)\n",
    "        aux2 = cirq.GridQubit(1, -1)\n",
    "        aux_qubits = [aux1, aux2]\n",
    "    else:\n",
    "        aux_qubits = []\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout,\n",
    "        dropout_aux_qubits=aux_qubits)\n",
    "\n",
    "    # Then add layers (TODO: experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx2\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2QZvVh7vojhx",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"4801.606640624999\" height=\"950.0\"><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"125.0\" y2=\"125.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"175.0\" y2=\"175.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"225.0\" y2=\"225.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"275.0\" y2=\"275.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"325.0\" y2=\"325.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"375.0\" y2=\"375.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"425.0\" y2=\"425.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"475.0\" y2=\"475.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"525.0\" y2=\"525.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"575.0\" y2=\"575.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"625.0\" y2=\"625.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"675.0\" y2=\"675.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"725.0\" y2=\"725.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"775.0\" y2=\"775.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"825.0\" y2=\"825.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"875.0\" y2=\"875.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"36.90890625\" x2=\"4771.606640624999\" y1=\"925.0\" y2=\"925.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"239.75384765625\" x2=\"239.75384765625\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"330.67544921875003\" x2=\"330.67544921875003\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"421.56314453125003\" x2=\"421.56314453125003\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"513.41880859375\" x2=\"513.41880859375\" y1=\"25.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"605.30509765625\" x2=\"605.30509765625\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"697.22857421875\" x2=\"697.22857421875\" y1=\"25.0\" y2=\"425.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"789.1695507812501\" x2=\"789.1695507812501\" y1=\"25.0\" y2=\"475.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"881.0733398437501\" x2=\"881.0733398437501\" y1=\"25.0\" y2=\"525.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"972.99025390625\" x2=\"972.99025390625\" y1=\"25.0\" y2=\"575.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1064.91701171875\" x2=\"1064.91701171875\" y1=\"25.0\" y2=\"625.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1160.7094921875\" x2=\"1160.7094921875\" y1=\"25.0\" y2=\"675.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1258.9009765625\" x2=\"1258.9009765625\" y1=\"25.0\" y2=\"725.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1357.0585546875\" x2=\"1357.0585546875\" y1=\"25.0\" y2=\"775.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1456.7003515625\" x2=\"1456.7003515625\" y1=\"25.0\" y2=\"825.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1556.3727734375\" x2=\"1556.3727734375\" y1=\"25.0\" y2=\"875.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1656.0823828125\" x2=\"1656.0823828125\" y1=\"25.0\" y2=\"925.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1751.00669921875\" x2=\"1751.00669921875\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1840.13728515625\" x2=\"1840.13728515625\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1929.23396484375\" x2=\"1929.23396484375\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2019.29861328125\" x2=\"2019.29861328125\" y1=\"25.0\" y2=\"275.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2109.3938867187503\" x2=\"2109.3938867187503\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2199.52634765625\" x2=\"2199.52634765625\" y1=\"25.0\" y2=\"425.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2289.67630859375\" x2=\"2289.67630859375\" y1=\"25.0\" y2=\"475.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2379.78908203125\" x2=\"2379.78908203125\" y1=\"25.0\" y2=\"525.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2469.91498046875\" x2=\"2469.91498046875\" y1=\"25.0\" y2=\"575.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2560.05072265625\" x2=\"2560.05072265625\" y1=\"25.0\" y2=\"625.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2654.0521875\" x2=\"2654.0521875\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2750.45265625\" x2=\"2750.45265625\" y1=\"25.0\" y2=\"725.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2846.81921875\" x2=\"2846.81921875\" y1=\"25.0\" y2=\"775.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2944.67\" x2=\"2944.67\" y1=\"25.0\" y2=\"825.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3042.55140625\" x2=\"3042.55140625\" y1=\"25.0\" y2=\"875.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3140.47\" x2=\"3140.47\" y1=\"25.0\" y2=\"925.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3235.39431640625\" x2=\"3235.39431640625\" y1=\"25.0\" y2=\"125.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3326.31591796875\" x2=\"3326.31591796875\" y1=\"25.0\" y2=\"175.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3417.2036132812495\" x2=\"3417.2036132812495\" y1=\"25.0\" y2=\"225.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3509.0592773437497\" x2=\"3509.0592773437497\" y1=\"25.0\" y2=\"325.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3600.94556640625\" x2=\"3600.94556640625\" y1=\"25.0\" y2=\"375.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3692.8690429687495\" x2=\"3692.8690429687495\" y1=\"25.0\" y2=\"425.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3784.8100195312495\" x2=\"3784.8100195312495\" y1=\"25.0\" y2=\"475.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3876.7138085937495\" x2=\"3876.7138085937495\" y1=\"25.0\" y2=\"525.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3968.6307226562494\" x2=\"3968.6307226562494\" y1=\"25.0\" y2=\"575.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"4060.5574804687494\" x2=\"4060.5574804687494\" y1=\"25.0\" y2=\"625.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"4156.349960937499\" x2=\"4156.349960937499\" y1=\"25.0\" y2=\"75.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"4254.5414453124995\" x2=\"4254.5414453124995\" y1=\"25.0\" y2=\"725.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"4352.6990234375\" x2=\"4352.6990234375\" y1=\"25.0\" y2=\"775.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"4452.340820312499\" x2=\"4452.340820312499\" y1=\"25.0\" y2=\"825.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"4552.013242187499\" x2=\"4552.013242187499\" y1=\"25.0\" y2=\"875.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"4651.722851562499\" x2=\"4651.722851562499\" y1=\"25.0\" y2=\"925.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"5.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"55.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, -1): </text><rect x=\"10.0\" y=\"105.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"155.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"205.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"10.0\" y=\"255.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 3): </text><rect x=\"10.0\" y=\"305.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, -1): </text><rect x=\"10.0\" y=\"355.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"405.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 1): </text><rect x=\"10.0\" y=\"455.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"475.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 2): </text><rect x=\"10.0\" y=\"505.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"525.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 3): </text><rect x=\"10.0\" y=\"555.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"605.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"625.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 1): </text><rect x=\"10.0\" y=\"655.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"675.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"705.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"725.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 3): </text><rect x=\"10.0\" y=\"755.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"775.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"10.0\" y=\"805.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"825.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"10.0\" y=\"855.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"875.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 2): </text><rect x=\"10.0\" y=\"905.0\" width=\"53.8178125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"36.90890625\" y=\"925.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 3): </text><rect x=\"83.8178125\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"103.8178125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"143.8178125\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"163.8178125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"203.8178125\" y=\"105.0\" width=\"71.8720703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"239.75384765625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_0</text><rect x=\"203.8178125\" y=\"5.0\" width=\"71.8720703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"239.75384765625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"295.68988281250006\" y=\"155.0\" width=\"69.9711328125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"330.67544921875003\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_1</text><rect x=\"295.68988281250006\" y=\"5.0\" width=\"69.9711328125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"330.67544921875003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"385.661015625\" y=\"205.0\" width=\"71.8042578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"421.56314453125003\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_2</text><rect x=\"385.661015625\" y=\"5.0\" width=\"71.8042578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"421.56314453125003\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"477.4652734375\" y=\"255.0\" width=\"71.9070703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"513.41880859375\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_3</text><rect x=\"477.4652734375\" y=\"5.0\" width=\"71.9070703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"513.41880859375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"569.37234375\" y=\"355.0\" width=\"71.8655078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"605.30509765625\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_4</text><rect x=\"569.37234375\" y=\"5.0\" width=\"71.8655078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"605.30509765625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"661.2378515625\" y=\"405.0\" width=\"71.9814453125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"697.22857421875\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_5</text><rect x=\"661.2378515625\" y=\"5.0\" width=\"71.9814453125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"697.22857421875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"753.219296875\" y=\"455.0\" width=\"71.9005078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"789.1695507812501\" y=\"475.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_6</text><rect x=\"753.219296875\" y=\"5.0\" width=\"71.9005078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"789.1695507812501\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"845.1198046875\" y=\"505.0\" width=\"71.9070703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"881.0733398437501\" y=\"525.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_7</text><rect x=\"845.1198046875\" y=\"5.0\" width=\"71.9070703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"881.0733398437501\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"937.026875\" y=\"555.0\" width=\"71.9267578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"972.99025390625\" y=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_8</text><rect x=\"937.026875\" y=\"5.0\" width=\"71.9267578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"972.99025390625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1028.9536328125\" y=\"605.0\" width=\"71.9267578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1064.91701171875\" y=\"625.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_9</text><rect x=\"1028.9536328125\" y=\"5.0\" width=\"71.9267578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1064.91701171875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1120.880390625\" y=\"655.0\" width=\"79.658203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1160.7094921875\" y=\"675.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_10</text><rect x=\"1120.880390625\" y=\"5.0\" width=\"79.658203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1160.7094921875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1220.53859375\" y=\"705.0\" width=\"76.724765625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1258.9009765625\" y=\"725.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_11</text><rect x=\"1220.53859375\" y=\"5.0\" width=\"76.724765625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1258.9009765625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1317.263359375\" y=\"755.0\" width=\"79.59039062500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1357.0585546875\" y=\"775.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_12</text><rect x=\"1317.263359375\" y=\"5.0\" width=\"79.59039062500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1357.0585546875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1416.85375\" y=\"805.0\" width=\"79.69320312500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1456.7003515625\" y=\"825.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_13</text><rect x=\"1416.85375\" y=\"5.0\" width=\"79.69320312500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1456.7003515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1516.546953125\" y=\"855.0\" width=\"79.651640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1556.3727734375\" y=\"875.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_14</text><rect x=\"1516.546953125\" y=\"5.0\" width=\"79.651640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1556.3727734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1616.19859375\" y=\"905.0\" width=\"79.767578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1656.0823828125\" y=\"925.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_15</text><rect x=\"1616.19859375\" y=\"5.0\" width=\"79.767578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1656.0823828125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1715.966171875\" y=\"105.0\" width=\"70.0810546875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1751.00669921875\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_0</text><rect x=\"1715.966171875\" y=\"5.0\" width=\"70.0810546875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1751.00669921875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1806.0472265625\" y=\"155.0\" width=\"68.1801171875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1840.13728515625\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_1</text><rect x=\"1806.0472265625\" y=\"5.0\" width=\"68.1801171875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1840.13728515625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1894.22734375\" y=\"205.0\" width=\"70.0132421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1929.23396484375\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_2</text><rect x=\"1894.22734375\" y=\"5.0\" width=\"70.0132421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1929.23396484375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"1984.2405859375\" y=\"255.0\" width=\"70.1160546875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2019.29861328125\" y=\"275.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_3</text><rect x=\"1984.2405859375\" y=\"5.0\" width=\"70.1160546875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2019.29861328125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2074.356640625\" y=\"355.0\" width=\"70.0744921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2109.3938867187503\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_4</text><rect x=\"2074.356640625\" y=\"5.0\" width=\"70.0744921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2109.3938867187503\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2164.4311328125\" y=\"405.0\" width=\"70.1904296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2199.52634765625\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_5</text><rect x=\"2164.4311328125\" y=\"5.0\" width=\"70.1904296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2199.52634765625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2254.6215625\" y=\"455.0\" width=\"70.1094921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2289.67630859375\" y=\"475.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_6</text><rect x=\"2254.6215625\" y=\"5.0\" width=\"70.1094921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2289.67630859375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2344.7310546875\" y=\"505.0\" width=\"70.1160546875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2379.78908203125\" y=\"525.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_7</text><rect x=\"2344.7310546875\" y=\"5.0\" width=\"70.1160546875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2379.78908203125\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2434.847109375\" y=\"555.0\" width=\"70.1357421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2469.91498046875\" y=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_8</text><rect x=\"2434.847109375\" y=\"5.0\" width=\"70.1357421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2469.91498046875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2524.9828515625\" y=\"605.0\" width=\"70.1357421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2560.05072265625\" y=\"625.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_9</text><rect x=\"2524.9828515625\" y=\"5.0\" width=\"70.1357421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2560.05072265625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2615.11859375\" y=\"55.0\" width=\"77.8671875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2654.0521875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_10</text><rect x=\"2615.11859375\" y=\"5.0\" width=\"77.8671875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2654.0521875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2712.98578125\" y=\"705.0\" width=\"74.93375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2750.45265625\" y=\"725.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_11</text><rect x=\"2712.98578125\" y=\"5.0\" width=\"74.93375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2750.45265625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2807.91953125\" y=\"755.0\" width=\"77.79937500000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2846.81921875\" y=\"775.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_12</text><rect x=\"2807.91953125\" y=\"5.0\" width=\"77.79937500000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2846.81921875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2905.71890625\" y=\"805.0\" width=\"77.90218750000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2944.67\" y=\"825.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_13</text><rect x=\"2905.71890625\" y=\"5.0\" width=\"77.90218750000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2944.67\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3003.62109375\" y=\"855.0\" width=\"77.860625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3042.55140625\" y=\"875.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_14</text><rect x=\"3003.62109375\" y=\"5.0\" width=\"77.860625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3042.55140625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3101.48171875\" y=\"905.0\" width=\"77.9765625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3140.47\" y=\"925.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_15</text><rect x=\"3101.48171875\" y=\"5.0\" width=\"77.9765625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3140.47\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3199.45828125\" y=\"105.0\" width=\"71.8720703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3235.39431640625\" y=\"125.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_0</text><rect x=\"3199.45828125\" y=\"5.0\" width=\"71.8720703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3235.39431640625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"3291.3303515625\" y=\"155.0\" width=\"69.9711328125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3326.31591796875\" y=\"175.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_1</text><rect x=\"3291.3303515625\" y=\"5.0\" width=\"69.9711328125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3326.31591796875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"3381.3014843749997\" y=\"205.0\" width=\"71.8042578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3417.2036132812495\" y=\"225.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_2</text><rect x=\"3381.3014843749997\" y=\"5.0\" width=\"71.8042578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3417.2036132812495\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"3473.1057421875\" y=\"305.0\" width=\"71.9070703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3509.0592773437497\" y=\"325.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_3</text><rect x=\"3473.1057421875\" y=\"5.0\" width=\"71.9070703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3509.0592773437497\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"3565.0128124999997\" y=\"355.0\" width=\"71.8655078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3600.94556640625\" y=\"375.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_4</text><rect x=\"3565.0128124999997\" y=\"5.0\" width=\"71.8655078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3600.94556640625\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"3656.8783203124995\" y=\"405.0\" width=\"71.9814453125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3692.8690429687495\" y=\"425.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_5</text><rect x=\"3656.8783203124995\" y=\"5.0\" width=\"71.9814453125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3692.8690429687495\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"3748.8597656249995\" y=\"455.0\" width=\"71.9005078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3784.8100195312495\" y=\"475.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_6</text><rect x=\"3748.8597656249995\" y=\"5.0\" width=\"71.9005078125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3784.8100195312495\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"3840.7602734374996\" y=\"505.0\" width=\"71.9070703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3876.7138085937495\" y=\"525.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_7</text><rect x=\"3840.7602734374996\" y=\"5.0\" width=\"71.9070703125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3876.7138085937495\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"3932.6673437499994\" y=\"555.0\" width=\"71.9267578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3968.6307226562494\" y=\"575.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_8</text><rect x=\"3932.6673437499994\" y=\"5.0\" width=\"71.9267578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3968.6307226562494\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"4024.5941015624994\" y=\"605.0\" width=\"71.9267578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4060.5574804687494\" y=\"625.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_9</text><rect x=\"4024.5941015624994\" y=\"5.0\" width=\"71.9267578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4060.5574804687494\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"4116.520859374999\" y=\"55.0\" width=\"79.658203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4156.349960937499\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_10</text><rect x=\"4116.520859374999\" y=\"5.0\" width=\"79.658203125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4156.349960937499\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"4216.179062499999\" y=\"705.0\" width=\"76.724765625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4254.5414453124995\" y=\"725.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_11</text><rect x=\"4216.179062499999\" y=\"5.0\" width=\"76.724765625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4254.5414453124995\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"4312.903828125\" y=\"755.0\" width=\"79.59039062500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4352.6990234375\" y=\"775.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_12</text><rect x=\"4312.903828125\" y=\"5.0\" width=\"79.59039062500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4352.6990234375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"4412.494218749999\" y=\"805.0\" width=\"79.69320312500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4452.340820312499\" y=\"825.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_13</text><rect x=\"4412.494218749999\" y=\"5.0\" width=\"79.69320312500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4452.340820312499\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"4512.187421874999\" y=\"855.0\" width=\"79.651640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4552.013242187499\" y=\"875.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_14</text><rect x=\"4512.187421874999\" y=\"5.0\" width=\"79.651640625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4552.013242187499\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"4611.839062499999\" y=\"905.0\" width=\"79.767578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4651.722851562499\" y=\"925.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx2_15</text><rect x=\"4611.839062499999\" y=\"5.0\" width=\"79.767578125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4651.722851562499\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"4711.606640624999\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"4731.606640624999\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7f916d1963a0>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_circuit, model_readout = create_quantum_model(apply_dropout=True)\n",
    "SVGCircuit(model_circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LY7vbY6yfABE"
   },
   "source": [
    "### 2.2 Wrap the model-circuit in a tfq-keras model\n",
    "\n",
    "Build the Keras model with the quantum components. This model is fed the \"quantum data\", from `x_train_circ`, that encodes the classical data. It uses a *Parametrized Quantum Circuit* layer, `tfq.layers.PQC`, to train the model circuit, on the quantum data.\n",
    "\n",
    "To classify these images, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed taking the expectation of a readout qubit in a parameterized circuit. The expectation returns a value between 1 and -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZYdf_KOxojh0",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# Build the Keras model.\n",
    "qlayer = tfq.layers.PQC(model_circuit, model_readout)\n",
    "print(len(qlayer.get_weights()[0]))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # The input is the data-circuit, encoded as a tf.string\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
    "    qlayer,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jz-FbVc9ojh3"
   },
   "source": [
    "Next, describe the training procedure to the model, using the `compile` method.\n",
    "\n",
    "Since the the expected readout is in the range `[-1,1]`, optimizing the hinge loss is a somewhat natural fit. \n",
    "\n",
    "Note: Another valid approach would be to shift the output range to `[0,1]`, and treat it as the probability the model assigns to class `3`. This could be used with a standard a `tf.losses.BinaryCrossentropy` loss.\n",
    "\n",
    "To use the hinge loss here you need to make two small adjustments. First convert the labels, `y_train_nocon`, from boolean to `[-1,1]`, as expected by the hinge loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CgMNkC1Fojh5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "y_train_hinge = 2.0*y_train_nocon-1.0\n",
    "y_test_hinge = 2.0*y_test-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nwnveDiojh7"
   },
   "source": [
    "Second, use a custiom `hinge_accuracy` metric that correctly handles `[-1, 1]` as the `y_true` labels argument. \n",
    "`tf.losses.BinaryAccuracy(threshold=0.0)` expects `y_true` to be a boolean, and so can't be used with hinge loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3XKtZ_TEojh8",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def hinge_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true) > 0.0\n",
    "    y_pred = tf.squeeze(y_pred) > 0.0\n",
    "    result = tf.cast(y_true == y_pred, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "FlpETlLRojiA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.Hinge(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[hinge_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jkHq2RstojiC",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pqc (PQC)                    (None, 1)                 48        \n",
      "=================================================================\n",
      "Total params: 48\n",
      "Trainable params: 48\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsuOzDYblA9s"
   },
   "source": [
    "### Train the quantum model\n",
    "\n",
    "Now train the model—this takes about 45 min. If you don't want to wait that long, use a small subset of the data (set `NUM_EXAMPLES=500`, below). This doesn't really affect the model's progress during training (it only has 32 parameters, and doesn't need much data to constrain these). Using fewer examples just ends training earlier (5min), but runs long enough to show that it is making progress in the validation logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "n8vuQpSLlBV2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "EPOCHS = 3\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_EXAMPLES = len(x_train_tfcirc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qJnNG-3JojiI",
    "tags": []
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
    "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMSdgGC1GL7D"
   },
   "source": [
    "Training this model to convergence should achieve >85% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(apply_dropout=False):\n",
    "    for i in range(EPOCHS):\n",
    "        # HACK - build new quantum circuit for each epoch and copy over the weights from the old one\n",
    "        model_circuit, model_readout = create_quantum_model(apply_dropout)\n",
    "\n",
    "        if i == 0:\n",
    "            qlayer = tfq.layers.PQC(model_circuit, model_readout)\n",
    "        else:\n",
    "            qlayer_new = tfq.layers.PQC(model_circuit, model_readout,\n",
    "                                             initializer=tf.keras.initializers.Zeros)\n",
    "            qlayer_new.set_weights(qlayer.get_weights())\n",
    "            qlayer = qlayer_new\n",
    "\n",
    "        model = tf.keras.Sequential([\n",
    "            tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "            qlayer,\n",
    "        ])\n",
    "        model.compile(\n",
    "            loss=tf.keras.losses.Hinge(),\n",
    "            optimizer=tf.keras.optimizers.Adam(),\n",
    "            metrics=[hinge_accuracy])\n",
    "\n",
    "        # Now fit the model for this epoch\n",
    "        model.fit(\n",
    "              x_train_tfcirc_sub, y_train_hinge_sub,\n",
    "              batch_size=32,\n",
    "              epochs=1,\n",
    "              verbose=1,\n",
    "              validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "324/324 [==============================] - 718s 2s/step - loss: 0.8489 - hinge_accuracy: 0.6852 - val_loss: 0.3843 - val_hinge_accuracy: 0.8291\n",
      "324/324 [==============================] - 768s 2s/step - loss: 0.3928 - hinge_accuracy: 0.8203 - val_loss: 0.3641 - val_hinge_accuracy: 0.8720\n",
      "324/324 [==============================] - 693s 2s/step - loss: 0.3812 - hinge_accuracy: 0.8626 - val_loss: 0.3530 - val_hinge_accuracy: 0.8947\n"
     ]
    }
   ],
   "source": [
    "model = train_model(apply_dropout=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Non-dropout training set perf:\n",
      "324/324 [==============================] - 102s 312ms/step - loss: 0.3630 - hinge_accuracy: 0.8839\n",
      "Non-dropout test set perf:\n",
      "62/62 [==============================] - 18s 281ms/step - loss: 0.3530 - hinge_accuracy: 0.8947\n"
     ]
    }
   ],
   "source": [
    "print(\"Non-dropout training set perf:\")\n",
    "model.evaluate(x_train_tfcirc_sub, y_train_hinge_sub)\n",
    "print(\"Non-dropout test set perf:\")\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ya9qP3KkojiM",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241/324 [=====================>........] - ETA: 11:03 - loss: 0.9432 - hinge_accuracy: 0.6362"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-c3c40dc7fa4f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdropout_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mapply_dropout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-30-4418fa65deea>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(apply_dropout)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;31m# Now fit the model for this epoch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         model.fit(\n\u001b[0m\u001b[1;32m     25\u001b[0m               \u001b[0mx_train_tfcirc_sub\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_hinge_sub\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m               \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2942\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1916\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1918\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1919\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    553\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 555\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    556\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "dropout_model = train_model(apply_dropout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dropout training set perf:\")\n",
    "dropout_model.evaluate(x_train_tfcirc_sub, y_train_hinge_sub)\n",
    "print(\"Dropout test set perf:\")\n",
    "qnn_results = dropout_model.evaluate(x_test_tfcirc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ER7B7aaojiP"
   },
   "source": [
    "Note: The training accuracy reports the average over the epoch. The validation accuracy is evaluated at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8952YvuWGL7J"
   },
   "source": [
    "## 3. Classical neural network\n",
    "\n",
    "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
    "\n",
    "In the following example, a classical neural network is used for for the 3-6 classification problem using the entire 28x28 image instead of subsampling the image. This easily converges to nearly 100% accuracy of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pZofEHhLGL7L",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CiAJl7sZojiU",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5-5BVJaojiZ"
   },
   "source": [
    "The above model has nearly 1.2M parameters. For a more fair comparison, try a 37-parameter model, on the subsampled images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "70TOM6r-ojiZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_fair_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_fair_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lA_Fx-8gojid",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.fit(x_train_bin,\n",
    "          y_train_nocon,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "fair_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH3mam7EGL7N"
   },
   "source": [
    "## 4. Comparison\n",
    "\n",
    "Higher resolution input and a more powerful model make this problem easy for the CNN. While a classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NOMeN7pMGL7P",
    "tags": []
   },
   "outputs": [],
   "source": [
    "qnn_accuracy = qnn_results[1]\n",
    "cnn_accuracy = cnn_results[1]\n",
    "fair_nn_accuracy = fair_nn_results[1]\n",
    "\n",
    "sns.barplot([\"Quantum\", \"Classical, full\", \"Classical, fair\"],\n",
    "            [qnn_accuracy, cnn_accuracy, fair_nn_accuracy])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logdir = \"tb_logs/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "file_writer = tf.summary.create_file_writer(logdir + \"/metrics\")\n",
    "file_writer.set_as_default()"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
