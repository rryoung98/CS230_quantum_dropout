{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xLOXFOT5Q40E"
   },
   "source": [
    "##### Copyright 2020 The TensorFlow Authors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "cellView": "form",
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:07:36.004926Z",
     "iopub.status.busy": "2021-03-28T11:07:36.004376Z",
     "iopub.status.idle": "2021-03-28T11:07:36.006006Z",
     "shell.execute_reply": "2021-03-28T11:07:36.006475Z"
    },
    "id": "iiQkM5ZgQ8r2"
   },
   "outputs": [],
   "source": [
    "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "# https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "j6331ZSsQGY3"
   },
   "source": [
    "# MNIST classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i9Jcnb8bQQyd"
   },
   "source": [
    "Based on https://www.tensorflow.org/quantum/tutorials/mnist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "udLObUVeGfTs"
   },
   "source": [
    "We build a quantum neural network (QNN) to classify a simplified version of MNIST, similar to the approach used in <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al</a>. The performance of the quantum neural network on this classical data problem is compared with a classical neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X35qHdh5Gzqg"
   },
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:07:36.016715Z",
     "iopub.status.busy": "2021-03-28T11:07:36.016103Z",
     "iopub.status.idle": "2021-03-28T11:07:55.893943Z",
     "shell.execute_reply": "2021-03-28T11:07:55.893388Z"
    },
    "id": "TorxE5tnkvb2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\r\n",
      "tfq-nightly 0.5.0.dev20210516 requires grpcio==1.30.0, but you have grpcio 1.32.0 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -q tensorflow==2.3.1\n",
    "!python3.8 -m pip install -q tensorflow==2.4.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FxkQA6oblNqI"
   },
   "source": [
    "Install TensorFlow Quantum:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:07:55.900159Z",
     "iopub.status.busy": "2021-03-28T11:07:55.898351Z",
     "iopub.status.idle": "2021-03-28T11:08:06.132407Z",
     "shell.execute_reply": "2021-03-28T11:08:06.131886Z"
    },
    "id": "saFHsRDpkvkH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tfq-nightly in ./qenv_project/lib/python3.8/site-packages (0.5.0.dev20210516)\n",
      "Requirement already satisfied: cirq==0.11.0 in ./qenv_project/lib/python3.8/site-packages (from tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: protobuf==3.13.0 in ./qenv_project/lib/python3.8/site-packages (from tfq-nightly) (3.13.0)\n",
      "Collecting grpcio==1.30.0\n",
      "  Using cached grpcio-1.30.0-cp38-cp38-manylinux2010_x86_64.whl (3.0 MB)\n",
      "Requirement already satisfied: sympy==1.5 in ./qenv_project/lib/python3.8/site-packages (from tfq-nightly) (1.5)\n",
      "Requirement already satisfied: googleapis-common-protos==1.52.0 in ./qenv_project/lib/python3.8/site-packages (from tfq-nightly) (1.52.0)\n",
      "Requirement already satisfied: google-auth==1.18.0 in ./qenv_project/lib/python3.8/site-packages (from tfq-nightly) (1.18.0)\n",
      "Requirement already satisfied: google-api-core==1.21.0 in ./qenv_project/lib/python3.8/site-packages (from tfq-nightly) (1.21.0)\n",
      "Requirement already satisfied: cirq-core==0.11.0 in ./qenv_project/lib/python3.8/site-packages (from cirq==0.11.0->tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: cirq-google==0.11.0 in ./qenv_project/lib/python3.8/site-packages (from cirq==0.11.0->tfq-nightly) (0.11.0)\n",
      "Requirement already satisfied: matplotlib~=3.0 in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (3.4.2)\n",
      "Requirement already satisfied: numpy~=1.16 in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.19.5)\n",
      "Requirement already satisfied: requests~=2.18 in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.25.1)\n",
      "Requirement already satisfied: networkx~=2.4 in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.5.1)\n",
      "Requirement already satisfied: tqdm in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.60.0)\n",
      "Requirement already satisfied: pandas in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.2.4)\n",
      "Requirement already satisfied: scipy in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.6.3)\n",
      "Requirement already satisfied: typing-extensions in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (3.7.4.3)\n",
      "Requirement already satisfied: sortedcontainers~=2.0 in ./qenv_project/lib/python3.8/site-packages (from cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.4.0)\n",
      "Requirement already satisfied: setuptools>=34.0.0 in ./qenv_project/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (56.2.0)\n",
      "Requirement already satisfied: pytz in ./qenv_project/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (2021.1)\n",
      "Requirement already satisfied: six>=1.10.0 in ./qenv_project/lib/python3.8/site-packages (from google-api-core==1.21.0->tfq-nightly) (1.15.0)\n",
      "Requirement already satisfied: cachetools<5.0,>=2.0.0 in ./qenv_project/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (4.2.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./qenv_project/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (4.7.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./qenv_project/lib/python3.8/site-packages (from google-auth==1.18.0->tfq-nightly) (0.2.8)\n",
      "Requirement already satisfied: mpmath>=0.19 in ./qenv_project/lib/python3.8/site-packages (from sympy==1.5->tfq-nightly) (1.2.1)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in ./qenv_project/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.3.1)\n",
      "Requirement already satisfied: cycler>=0.10 in ./qenv_project/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in ./qenv_project/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (8.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in ./qenv_project/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in ./qenv_project/lib/python3.8/site-packages (from matplotlib~=3.0->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.8.1)\n",
      "Requirement already satisfied: decorator<5,>=4.3 in ./qenv_project/lib/python3.8/site-packages (from networkx~=2.4->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.4.2)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in ./qenv_project/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth==1.18.0->tfq-nightly) (0.4.8)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./qenv_project/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2.10)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in ./qenv_project/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (4.0.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./qenv_project/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (2020.12.5)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./qenv_project/lib/python3.8/site-packages (from requests~=2.18->cirq-core==0.11.0->cirq==0.11.0->tfq-nightly) (1.26.4)\n",
      "Installing collected packages: grpcio\n",
      "  Attempting uninstall: grpcio\n",
      "    Found existing installation: grpcio 1.32.0\n",
      "    Uninstalling grpcio-1.32.0:\n",
      "      Successfully uninstalled grpcio-1.32.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "tensorflow 2.4.1 requires grpcio~=1.32.0, but you have grpcio 1.30.0 which is incompatible.\u001b[0m\n",
      "Successfully installed grpcio-1.30.0\n"
     ]
    }
   ],
   "source": [
    "#!pip3 install -q tensorflow-quantum\n",
    "!python3.8 -m pip install tfq-nightly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdgMMZEBGqyl"
   },
   "source": [
    "Now import TensorFlow and the module dependencies:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:06.138578Z",
     "iopub.status.busy": "2021-03-28T11:08:06.137952Z",
     "iopub.status.idle": "2021-03-28T11:08:13.897818Z",
     "shell.execute_reply": "2021-03-28T11:08:13.897267Z"
    },
    "id": "enZ300Bflq80"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_quantum as tfq\n",
    "\n",
    "import cirq\n",
    "import sympy\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import collections\n",
    "\n",
    "# visualization tools\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from cirq.contrib.svg import SVGCircuit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "b08Mmbs8lr81"
   },
   "source": [
    "## 1. Load the data\n",
    "\n",
    "In this tutorial you will build a binary classifier to distinguish between the digits 3 and 6, following <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> This section covers the data handling that:\n",
    "\n",
    "- Loads the raw data from Keras.\n",
    "- Filters the dataset to only 3s and 6s.\n",
    "- Downscales the images so they fit can fit in a quantum computer.\n",
    "- Removes any contradictory examples.\n",
    "- Converts the binary images to Cirq circuits.\n",
    "- Converts the Cirq circuits to TensorFlow Quantum circuits. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pDUdGxn-ojgy"
   },
   "source": [
    "### 1.1 Load the raw data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "xZyGXlaKojgz"
   },
   "source": [
    "Load the MNIST dataset distributed with Keras. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:13.903284Z",
     "iopub.status.busy": "2021-03-28T11:08:13.902683Z",
     "iopub.status.idle": "2021-03-28T11:08:14.530137Z",
     "shell.execute_reply": "2021-03-28T11:08:14.530513Z"
    },
    "id": "d9OSExvCojg0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of original training examples: 60000\n",
      "Number of original test examples: 10000\n"
     ]
    }
   ],
   "source": [
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "# Rescale the images from [0,255] to the [0.0,1.0] range.\n",
    "x_train, x_test = x_train[..., np.newaxis]/255.0, x_test[..., np.newaxis]/255.0\n",
    "\n",
    "print(\"Number of original training examples:\", len(x_train))\n",
    "print(\"Number of original test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fZpbygdGojg3"
   },
   "source": [
    "Filter the dataset to keep just the 3s and 6s,  remove the other classes. At the same time convert the label, `y`, to boolean: `True` for `3` and `False` for 6. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:14.535364Z",
     "iopub.status.busy": "2021-03-28T11:08:14.534791Z",
     "iopub.status.idle": "2021-03-28T11:08:14.536812Z",
     "shell.execute_reply": "2021-03-28T11:08:14.536398Z"
    },
    "id": "hOw68cCZojg4"
   },
   "outputs": [],
   "source": [
    "def filter_36(x, y):\n",
    "    keep = (y == 3) | (y == 6)\n",
    "    x, y = x[keep], y[keep]\n",
    "    y = y == 3\n",
    "    return x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:14.540890Z",
     "iopub.status.busy": "2021-03-28T11:08:14.540341Z",
     "iopub.status.idle": "2021-03-28T11:08:14.573341Z",
     "shell.execute_reply": "2021-03-28T11:08:14.572889Z"
    },
    "id": "p-XEU8egGL6q"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of filtered training examples: 12049\n",
      "Number of filtered test examples: 1968\n"
     ]
    }
   ],
   "source": [
    "x_train, y_train = filter_36(x_train, y_train)\n",
    "x_test, y_test = filter_36(x_test, y_test)\n",
    "\n",
    "print(\"Number of filtered training examples:\", len(x_train))\n",
    "print(\"Number of filtered test examples:\", len(x_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3wyiaP0Xojg_"
   },
   "source": [
    "Show the first example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:14.596450Z",
     "iopub.status.busy": "2021-03-28T11:08:14.594716Z",
     "iopub.status.idle": "2021-03-28T11:08:14.745615Z",
     "shell.execute_reply": "2021-03-28T11:08:14.745161Z"
    },
    "id": "j5STP7MbojhA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fbf76a71460>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train[0, :, :, 0])\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wNS9sVPQojhC"
   },
   "source": [
    "### 1.2 Downscale the images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "fmmtplIFGL6t"
   },
   "source": [
    "An image size of 28x28 is much too large for current quantum computers. Resize the image down to 4x4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:14.805726Z",
     "iopub.status.busy": "2021-03-28T11:08:14.805078Z",
     "iopub.status.idle": "2021-03-28T11:08:14.825359Z",
     "shell.execute_reply": "2021-03-28T11:08:14.824846Z"
    },
    "id": "lbhUdBFWojhE",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "x_train_small = tf.image.resize(x_train, (4,4)).numpy()\n",
    "x_test_small = tf.image.resize(x_test, (4,4)).numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pOMd7zIjGL6x"
   },
   "source": [
    "Again, display the first training example—after resize: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:14.859442Z",
     "iopub.status.busy": "2021-03-28T11:08:14.847305Z",
     "iopub.status.idle": "2021-03-28T11:08:14.994157Z",
     "shell.execute_reply": "2021-03-28T11:08:14.993698Z"
    },
    "id": "YIYOtCRIGL6y",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x7fbf76934b80>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(y_train[0])\n",
    "\n",
    "plt.imshow(x_train_small[0,:,:,0], vmin=0, vmax=1)\n",
    "plt.colorbar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gGeF1_qtojhK"
   },
   "source": [
    "### 1.3 Remove contradictory examples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7ZLkq2yeojhL"
   },
   "source": [
    "From section *3.3 Learning to Distinguish Digits* of <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a>, filter the dataset to remove images that are labeled as belonging to both classes.\n",
    "\n",
    "This is not a standard machine-learning procedure, but is included in the interest of following the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:15.002678Z",
     "iopub.status.busy": "2021-03-28T11:08:15.002087Z",
     "iopub.status.idle": "2021-03-28T11:08:15.003654Z",
     "shell.execute_reply": "2021-03-28T11:08:15.003991Z"
    },
    "id": "LqOPW0C7ojhL"
   },
   "outputs": [],
   "source": [
    "def remove_contradicting(xs, ys):\n",
    "    mapping = collections.defaultdict(set)\n",
    "    orig_x = {}\n",
    "    # Determine the set of labels for each unique image:\n",
    "    for x,y in zip(xs,ys):\n",
    "       orig_x[tuple(x.flatten())] = x\n",
    "       mapping[tuple(x.flatten())].add(y)\n",
    "    \n",
    "    new_x = []\n",
    "    new_y = []\n",
    "    for flatten_x in mapping:\n",
    "      x = orig_x[flatten_x]\n",
    "      labels = mapping[flatten_x]\n",
    "      if len(labels) == 1:\n",
    "          new_x.append(x)\n",
    "          new_y.append(next(iter(labels)))\n",
    "      else:\n",
    "          # Throw out images that match more than one label.\n",
    "          pass\n",
    "    \n",
    "    num_uniq_3 = sum(1 for value in mapping.values() if len(value) == 1 and True in value)\n",
    "    num_uniq_6 = sum(1 for value in mapping.values() if len(value) == 1 and False in value)\n",
    "    num_uniq_both = sum(1 for value in mapping.values() if len(value) == 2)\n",
    "\n",
    "    print(\"Number of unique images:\", len(mapping.values()))\n",
    "    print(\"Number of unique 3s: \", num_uniq_3)\n",
    "    print(\"Number of unique 6s: \", num_uniq_6)\n",
    "    print(\"Number of unique contradicting labels (both 3 and 6): \", num_uniq_both)\n",
    "    print()\n",
    "    print(\"Initial number of images: \", len(xs))\n",
    "    print(\"Remaining non-contradicting unique images: \", len(new_x))\n",
    "    \n",
    "    return np.array(new_x), np.array(new_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "VMOiJfz_ojhP"
   },
   "source": [
    "The resulting counts do not closely match the reported values, but the exact procedure is not specified.\n",
    "\n",
    "It is also worth noting here that applying filtering contradictory examples at this point does not totally prevent the model from receiving contradictory training examples: the next step binarizes the data which will cause more collisions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:15.007881Z",
     "iopub.status.busy": "2021-03-28T11:08:15.007307Z",
     "iopub.status.idle": "2021-03-28T11:08:15.132502Z",
     "shell.execute_reply": "2021-03-28T11:08:15.132043Z"
    },
    "id": "zpnsAssWojhP",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 10387\n",
      "Number of unique 3s:  4912\n",
      "Number of unique 6s:  5426\n",
      "Number of unique contradicting labels (both 3 and 6):  49\n",
      "\n",
      "Initial number of images:  12049\n",
      "Remaining non-contradicting unique images:  10338\n"
     ]
    }
   ],
   "source": [
    "x_train_nocon, y_train_nocon = remove_contradicting(x_train_small, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ5NVaPojhT"
   },
   "source": [
    "### 1.4 Encode the data as quantum circuits\n",
    "\n",
    "To process images using a quantum computer, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed representing each pixel with a qubit, with the state depending on the value of the pixel. The first step is to convert to a binary encoding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:15.136578Z",
     "iopub.status.busy": "2021-03-28T11:08:15.136011Z",
     "iopub.status.idle": "2021-03-28T11:08:15.138975Z",
     "shell.execute_reply": "2021-03-28T11:08:15.138514Z"
    },
    "id": "1z8J7OyDojhV"
   },
   "outputs": [],
   "source": [
    "THRESHOLD = 0.5\n",
    "\n",
    "x_train_bin = np.array(x_train_nocon > THRESHOLD, dtype=np.float32)\n",
    "x_test_bin = np.array(x_test_small > THRESHOLD, dtype=np.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "SlJ5NVaPojhU"
   },
   "source": [
    "If you were to remove contradictory images at this point you would be left with only 193, likely not enough for effective training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:15.142687Z",
     "iopub.status.busy": "2021-03-28T11:08:15.142118Z",
     "iopub.status.idle": "2021-03-28T11:08:15.215301Z",
     "shell.execute_reply": "2021-03-28T11:08:15.214852Z"
    },
    "id": "1z8J7OyDojhW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique images: 193\n",
      "Number of unique 3s:  80\n",
      "Number of unique 6s:  69\n",
      "Number of unique contradicting labels (both 3 and 6):  44\n",
      "\n",
      "Initial number of images:  10338\n",
      "Remaining non-contradicting unique images:  149\n"
     ]
    }
   ],
   "source": [
    "_ = remove_contradicting(x_train_bin, y_train_nocon)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oLyxS9KlojhZ"
   },
   "source": [
    "The qubits at pixel indices with values that exceed a threshold, are rotated through an $X$ gate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:16.919035Z",
     "iopub.status.busy": "2021-03-28T11:08:15.799220Z",
     "iopub.status.idle": "2021-03-28T11:08:16.920766Z",
     "shell.execute_reply": "2021-03-28T11:08:16.920302Z"
    },
    "id": "aOu_3-3ZGL61"
   },
   "outputs": [],
   "source": [
    "def convert_to_circuit(image):\n",
    "    \"\"\"Encode truncated classical image into quantum datapoint.\"\"\"\n",
    "    values = np.ndarray.flatten(image)\n",
    "    qubits = cirq.GridQubit.rect(4, 4)\n",
    "    circuit = cirq.Circuit()\n",
    "    for i, value in enumerate(values):\n",
    "        if value:\n",
    "            circuit.append(cirq.X(qubits[i]))\n",
    "    return circuit\n",
    "\n",
    "\n",
    "x_train_circ = [convert_to_circuit(x) for x in x_train_bin]\n",
    "x_test_circ = [convert_to_circuit(x) for x in x_test_bin]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "zSCXqzOzojhd"
   },
   "source": [
    "Here is the circuit created for the first example (circuit diagrams do not show qubits with zero gates):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:16.932670Z",
     "iopub.status.busy": "2021-03-28T11:08:16.932091Z",
     "iopub.status.idle": "2021-03-28T11:08:16.970657Z",
     "shell.execute_reply": "2021-03-28T11:08:16.971035Z"
    },
    "id": "w3POmUEUojhe",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "findfont: Font family ['Arial'] not found. Falling back to DejaVu Sans.\n"
     ]
    },
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"169.517734375\" height=\"100.0\"><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"25.0\" y2=\"25.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"34.7588671875\" x2=\"139.517734375\" y1=\"75.0\" y2=\"75.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><rect x=\"10.0\" y=\"5.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"55.0\" width=\"49.517734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"34.7588671875\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"79.517734375\" y=\"5.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"25.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"79.517734375\" y=\"55.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"99.517734375\" y=\"75.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7fbf7690ee50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SVGCircuit(x_train_circ[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "AEQMxCcBojhg"
   },
   "source": [
    "Compare this circuit to the indices where the image value exceeds the threshold:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:16.975997Z",
     "iopub.status.busy": "2021-03-28T11:08:16.975415Z",
     "iopub.status.idle": "2021-03-28T11:08:16.977674Z",
     "shell.execute_reply": "2021-03-28T11:08:16.978102Z"
    },
    "id": "TBIsiXdtojhh"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2, 2],\n",
       "       [3, 1]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bin_img = x_train_bin[0,:,:,0]\n",
    "indices = np.array(np.where(bin_img)).T\n",
    "indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mWZ24w1Oojhk"
   },
   "source": [
    "Convert these `Cirq` circuits to tensors for `tfq`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:17.047434Z",
     "iopub.status.busy": "2021-03-28T11:08:17.011392Z",
     "iopub.status.idle": "2021-03-28T11:08:20.365846Z",
     "shell.execute_reply": "2021-03-28T11:08:20.366242Z"
    },
    "id": "IZStEMk4ojhk"
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc = tfq.convert_to_tensor(x_train_circ)\n",
    "x_test_tfcirc = tfq.convert_to_tensor(x_test_circ)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "4USiqeOqGL67"
   },
   "source": [
    "## 2. Quantum neural network\n",
    "\n",
    "There is little guidance for a quantum circuit structure that classifies images. Since the classification is based on the expectation of the readout qubit, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> propose using two qubit gates, with the readout qubit always acted upon. This is similar in some ways to running small a <a href=\"https://arxiv.org/abs/1511.06464\" class=\"external\">Unitary RNN</a> across the pixels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "knIzawEeojho"
   },
   "source": [
    "### 2.1 Build the model circuit\n",
    "\n",
    "This following example shows this layered approach. Each layer uses *n* instances of the same gate, with each of the data qubits acting on the readout qubit.\n",
    "\n",
    "Start with a simple class that will add a layer of these gates to a circuit:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:20.372031Z",
     "iopub.status.busy": "2021-03-28T11:08:20.371470Z",
     "iopub.status.idle": "2021-03-28T11:08:20.373416Z",
     "shell.execute_reply": "2021-03-28T11:08:20.372969Z"
    },
    "id": "-hjxxgU5ojho"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([cirq.X, cirq.XX, cirq.Y, cirq.YY, cirq.Z, cirq.ZZ, cirq.H, cirq.CZ, cirq.CNOT, cirq.SWAP, cirq.ISWAP, cirq.PhasedXPowGate(phase_exponent=0.123), cirq.PhasedISwapPowGate(phase_exponent=0.123), cirq.FSimGate(theta=0.123, phi=0.456), cirq.I])\n",
      "dict_keys([cirq.depolarize(p=0.01), cirq.asymmetric_depolarize(error_probabilities={'I': 0.94, 'X': 0.01, 'Y': 0.02, 'Z': 0.03}), cirq.generalized_amplitude_damp(p=0.01,gamma=0.02), cirq.amplitude_damp(gamma=0.01), cirq.ResetChannel(), cirq.phase_damp(gamma=0.01), cirq.phase_flip(p=0.01), cirq.bit_flip(p=0.01)])\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(tfq.util.get_supported_gates().keys())\n",
    "print(tfq.util.get_supported_channels().keys())\n",
    "\n",
    "symbol = sympy.Symbol('a_1')\n",
    "res = symbol * -1\n",
    "print(isinstance(res, sympy.Basic))\n",
    "\n",
    "class CircuitLayerBuilder():\n",
    "    def __init__(self, data_qubits, readout):\n",
    "        self.data_qubits = data_qubits\n",
    "        self.readout = readout\n",
    "    \n",
    "    def add_layer(self, circuit, gate, prefix):\n",
    "        dropout_id = np.random.randint(0, len(self.data_qubits) + 1)\n",
    "        for i, qubit in enumerate(self.data_qubits):\n",
    "            symbol = sympy.Symbol(prefix + '_' + str(i))\n",
    "            circuit.append(gate(qubit, self.readout)**symbol)\n",
    "            if i == dropout_id:\n",
    "                circuit.append(cirq.reset(qubit))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Sjo5hANFojhr"
   },
   "source": [
    "Build an example circuit layer to see how it looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:20.380672Z",
     "iopub.status.busy": "2021-03-28T11:08:20.380109Z",
     "iopub.status.idle": "2021-03-28T11:08:20.496527Z",
     "shell.execute_reply": "2021-03-28T11:08:20.496004Z"
    },
    "id": "SzXWOpUGojhs"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"526.7628125000001\" height=\"290.0\"><line x1=\"39.810625\" x2=\"496.76281250000005\" y1=\"45.0\" y2=\"45.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"496.76281250000005\" y1=\"95.0\" y2=\"95.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"496.76281250000005\" y1=\"145.0\" y2=\"145.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"496.76281250000005\" y1=\"195.0\" y2=\"195.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"496.76281250000005\" y1=\"245.0\" y2=\"245.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"171.663671875\" x2=\"293.34296875\" y1=\"5.0\" y2=\"5.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"171.663671875\" x2=\"293.34296875\" y1=\"285.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"125.6424609375\" x2=\"125.6424609375\" y1=\"45.0\" y2=\"95.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"247.50332031250002\" x2=\"247.50332031250002\" y1=\"45.0\" y2=\"145.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"349.1279296875\" x2=\"349.1279296875\" y1=\"45.0\" y2=\"195.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"440.8378515625001\" x2=\"440.8378515625001\" y1=\"45.0\" y2=\"245.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"171.663671875\" x2=\"171.663671875\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"293.34296875\" x2=\"293.34296875\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"171.663671875\" x2=\"171.663671875\" y1=\"275.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"293.34296875\" x2=\"293.34296875\" y1=\"275.0\" y2=\"285.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"25.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"75.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"125.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"175.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"225.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"89.62125\" y=\"75.0\" width=\"72.042421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"125.6424609375\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_0</text><rect x=\"89.62125\" y=\"25.0\" width=\"72.042421875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"125.6424609375\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"171.663671875\" y=\"75.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"191.663671875\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">R</text><rect x=\"211.66367187500003\" y=\"125.0\" width=\"71.679296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"247.50332031250002\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_1</text><rect x=\"211.66367187500003\" y=\"25.0\" width=\"71.679296875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"247.50332031250002\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"313.34296875\" y=\"175.0\" width=\"71.569921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"349.1279296875\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_2</text><rect x=\"313.34296875\" y=\"25.0\" width=\"71.569921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"349.1279296875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"404.91289062500005\" y=\"225.0\" width=\"71.849921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"440.8378515625001\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx_3</text><rect x=\"404.91289062500005\" y=\"25.0\" width=\"71.849921875\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"440.8378515625001\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7fbf76900190>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "demo_builder = CircuitLayerBuilder(data_qubits = cirq.GridQubit.rect(4,1),\n",
    "                                   readout=cirq.GridQubit(-1,-1))\n",
    "\n",
    "circuit = cirq.Circuit()\n",
    "demo_builder.add_layer(circuit, gate = cirq.XX, prefix='xx')\n",
    "SVGCircuit(circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "T-QhPE1pojhu"
   },
   "source": [
    "Now build a two-layered model, matching the data-circuit size, and include the preparation and readout operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:20.502090Z",
     "iopub.status.busy": "2021-03-28T11:08:20.501468Z",
     "iopub.status.idle": "2021-03-28T11:08:20.503138Z",
     "shell.execute_reply": "2021-03-28T11:08:20.503484Z"
    },
    "id": "JiALbpwRGL69"
   },
   "outputs": [],
   "source": [
    "def create_quantum_model():\n",
    "    \"\"\"Create a QNN model circuit and readout operation to go along with it.\"\"\"\n",
    "    data_qubits = cirq.GridQubit.rect(4, 4)  # a 4x4 grid.\n",
    "    readout = cirq.GridQubit(-1, -1)         # a single qubit at [-1,-1]\n",
    "    circuit = cirq.Circuit()\n",
    "    \n",
    "    # Prepare the readout qubit.\n",
    "    circuit.append(cirq.X(readout))\n",
    "    circuit.append(cirq.H(readout))\n",
    "    \n",
    "    builder = CircuitLayerBuilder(\n",
    "        data_qubits = data_qubits,\n",
    "        readout=readout)\n",
    "\n",
    "    # Then add layers (experiment by adding more).\n",
    "    builder.add_layer(circuit, cirq.XX, \"xx1\")\n",
    "    builder.add_layer(circuit, cirq.ZZ, \"zz1\")\n",
    "\n",
    "    # Finally, prepare the readout qubit.\n",
    "    circuit.append(cirq.H(readout))\n",
    "\n",
    "    return circuit, cirq.Z(readout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:20.518076Z",
     "iopub.status.busy": "2021-03-28T11:08:20.517492Z",
     "iopub.status.idle": "2021-03-28T11:08:20.519195Z",
     "shell.execute_reply": "2021-03-28T11:08:20.519564Z"
    },
    "id": "2QZvVh7vojhx"
   },
   "outputs": [
    {
     "data": {
      "image/svg+xml": [
       "<svg xmlns=\"http://www.w3.org/2000/svg\" width=\"3678.22171875\" height=\"890.0\"><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"45.0\" y2=\"45.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"95.0\" y2=\"95.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"145.0\" y2=\"145.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"195.0\" y2=\"195.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"245.0\" y2=\"245.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"295.0\" y2=\"295.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"345.0\" y2=\"345.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"395.0\" y2=\"395.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"445.0\" y2=\"445.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"495.0\" y2=\"495.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"545.0\" y2=\"545.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"595.0\" y2=\"595.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"645.0\" y2=\"645.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"695.0\" y2=\"695.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"745.0\" y2=\"745.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"795.0\" y2=\"795.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"39.810625\" x2=\"3648.22171875\" y1=\"845.0\" y2=\"845.0\" stroke=\"#1967d2\" stroke-width=\"1\" /><line x1=\"2695.123046875\" x2=\"2823.9590234375\" y1=\"5.0\" y2=\"5.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"2695.123046875\" x2=\"2823.9590234375\" y1=\"885.0\" y2=\"885.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"1756.0396093750003\" x2=\"1895.6033593750003\" y1=\"5.0\" y2=\"5.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"1756.0396093750003\" x2=\"1895.6033593750003\" y1=\"885.0\" y2=\"885.0\" stroke=\"black\" stroke-width=\"1\" /><line x1=\"250.09607421875\" x2=\"250.09607421875\" y1=\"45.0\" y2=\"95.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"350.86416015625\" x2=\"350.86416015625\" y1=\"45.0\" y2=\"145.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"451.39599609375006\" x2=\"451.39599609375006\" y1=\"45.0\" y2=\"195.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"552.0131445312501\" x2=\"552.0131445312501\" y1=\"45.0\" y2=\"245.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"652.9387304687501\" x2=\"652.9387304687501\" y1=\"45.0\" y2=\"295.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"753.8140039062502\" x2=\"753.8140039062502\" y1=\"45.0\" y2=\"345.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"854.6411523437502\" x2=\"854.6411523437502\" y1=\"45.0\" y2=\"395.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"955.4814257812501\" x2=\"955.4814257812501\" y1=\"45.0\" y2=\"445.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1056.2834179687502\" x2=\"1056.2834179687502\" y1=\"45.0\" y2=\"495.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1157.19150390625\" x2=\"1157.19150390625\" y1=\"45.0\" y2=\"545.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1262.567421875\" x2=\"1262.567421875\" y1=\"45.0\" y2=\"595.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1372.242734375\" x2=\"1372.242734375\" y1=\"45.0\" y2=\"645.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1481.6817968750001\" x2=\"1481.6817968750001\" y1=\"45.0\" y2=\"695.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1591.206171875\" x2=\"1591.206171875\" y1=\"45.0\" y2=\"745.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1701.0389843750002\" x2=\"1701.0389843750002\" y1=\"45.0\" y2=\"795.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1840.8214843750002\" x2=\"1840.8214843750002\" y1=\"45.0\" y2=\"845.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1955.0355664062504\" x2=\"1955.0355664062504\" y1=\"45.0\" y2=\"95.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2053.71841796875\" x2=\"2053.71841796875\" y1=\"45.0\" y2=\"145.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2152.1650195312504\" x2=\"2152.1650195312504\" y1=\"45.0\" y2=\"195.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2250.69693359375\" x2=\"2250.69693359375\" y1=\"45.0\" y2=\"245.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2349.53728515625\" x2=\"2349.53728515625\" y1=\"45.0\" y2=\"295.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2448.32732421875\" x2=\"2448.32732421875\" y1=\"45.0\" y2=\"345.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2547.0692382812504\" x2=\"2547.0692382812504\" y1=\"45.0\" y2=\"395.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2645.82427734375\" x2=\"2645.82427734375\" y1=\"45.0\" y2=\"445.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2774.54103515625\" x2=\"2774.54103515625\" y1=\"45.0\" y2=\"495.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2883.36388671875\" x2=\"2883.36388671875\" y1=\"45.0\" y2=\"545.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2986.6545703125003\" x2=\"2986.6545703125003\" y1=\"45.0\" y2=\"595.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3094.2446484375005\" x2=\"3094.2446484375005\" y1=\"45.0\" y2=\"645.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3201.5984765625003\" x2=\"3201.5984765625003\" y1=\"45.0\" y2=\"695.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3309.0376171875\" x2=\"3309.0376171875\" y1=\"45.0\" y2=\"745.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3416.7851953125\" x2=\"3416.7851953125\" y1=\"45.0\" y2=\"795.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"3524.4824609375\" x2=\"3524.4824609375\" y1=\"45.0\" y2=\"845.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2695.123046875\" x2=\"2695.123046875\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2823.9590234375\" x2=\"2823.9590234375\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2695.123046875\" x2=\"2695.123046875\" y1=\"875.0\" y2=\"885.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"2823.9590234375\" x2=\"2823.9590234375\" y1=\"875.0\" y2=\"885.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1756.0396093750003\" x2=\"1756.0396093750003\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1895.6033593750003\" x2=\"1895.6033593750003\" y1=\"5.0\" y2=\"15.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1756.0396093750003\" x2=\"1756.0396093750003\" y1=\"875.0\" y2=\"885.0\" stroke=\"black\" stroke-width=\"3\" /><line x1=\"1895.6033593750003\" x2=\"1895.6033593750003\" y1=\"875.0\" y2=\"885.0\" stroke=\"black\" stroke-width=\"3\" /><rect x=\"10.0\" y=\"25.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(-1, -1): </text><rect x=\"10.0\" y=\"75.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 0): </text><rect x=\"10.0\" y=\"125.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 1): </text><rect x=\"10.0\" y=\"175.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 2): </text><rect x=\"10.0\" y=\"225.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(0, 3): </text><rect x=\"10.0\" y=\"275.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"295.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 0): </text><rect x=\"10.0\" y=\"325.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"345.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 1): </text><rect x=\"10.0\" y=\"375.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"395.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 2): </text><rect x=\"10.0\" y=\"425.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"445.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(1, 3): </text><rect x=\"10.0\" y=\"475.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"495.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 0): </text><rect x=\"10.0\" y=\"525.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"545.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 1): </text><rect x=\"10.0\" y=\"575.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"595.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 2): </text><rect x=\"10.0\" y=\"625.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"645.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(2, 3): </text><rect x=\"10.0\" y=\"675.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"695.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 0): </text><rect x=\"10.0\" y=\"725.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"745.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 1): </text><rect x=\"10.0\" y=\"775.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"795.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 2): </text><rect x=\"10.0\" y=\"825.0\" width=\"59.62125\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"0\" /><text x=\"39.810625\" y=\"845.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">(3, 3): </text><rect x=\"89.62125\" y=\"25.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"109.62125\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">X</text><rect x=\"149.62125\" y=\"25.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"169.62125\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text><rect x=\"209.62125\" y=\"75.0\" width=\"80.94964843750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"250.09607421875\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_0</text><rect x=\"209.62125\" y=\"25.0\" width=\"80.94964843750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"250.09607421875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"310.57089843750003\" y=\"125.0\" width=\"80.5865234375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"350.86416015625\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_1</text><rect x=\"310.57089843750003\" y=\"25.0\" width=\"80.5865234375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"350.86416015625\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"411.15742187500007\" y=\"175.0\" width=\"80.4771484375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"451.39599609375006\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_2</text><rect x=\"411.15742187500007\" y=\"25.0\" width=\"80.4771484375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"451.39599609375006\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"511.63457031250005\" y=\"225.0\" width=\"80.7571484375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"552.0131445312501\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_3</text><rect x=\"511.63457031250005\" y=\"25.0\" width=\"80.7571484375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"552.0131445312501\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"612.3917187500001\" y=\"275.0\" width=\"81.09402343750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"652.9387304687501\" y=\"295.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_4</text><rect x=\"612.3917187500001\" y=\"25.0\" width=\"81.09402343750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"652.9387304687501\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"713.4857421875001\" y=\"325.0\" width=\"80.65652343750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"753.8140039062502\" y=\"345.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_5</text><rect x=\"713.4857421875001\" y=\"25.0\" width=\"80.65652343750001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"753.8140039062502\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"814.1422656250002\" y=\"375.0\" width=\"80.99777343750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"854.6411523437502\" y=\"395.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_6</text><rect x=\"814.1422656250002\" y=\"25.0\" width=\"80.99777343750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"854.6411523437502\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"915.1400390625001\" y=\"425.0\" width=\"80.6827734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"955.4814257812501\" y=\"445.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_7</text><rect x=\"915.1400390625001\" y=\"25.0\" width=\"80.6827734375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"955.4814257812501\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1015.8228125000002\" y=\"475.0\" width=\"80.9212109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1056.2834179687502\" y=\"495.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_8</text><rect x=\"1015.8228125000002\" y=\"25.0\" width=\"80.9212109375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1056.2834179687502\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1116.7440234375001\" y=\"525.0\" width=\"80.89496093750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1157.19150390625\" y=\"545.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_9</text><rect x=\"1116.7440234375001\" y=\"25.0\" width=\"80.89496093750002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1157.19150390625\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1217.638984375\" y=\"575.0\" width=\"89.85687500000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1262.567421875\" y=\"595.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_10</text><rect x=\"1217.638984375\" y=\"25.0\" width=\"89.85687500000002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1262.567421875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1327.495859375\" y=\"625.0\" width=\"89.49375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1372.242734375\" y=\"645.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_11</text><rect x=\"1327.495859375\" y=\"25.0\" width=\"89.49375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1372.242734375\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1436.989609375\" y=\"675.0\" width=\"89.384375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1481.6817968750001\" y=\"695.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_12</text><rect x=\"1436.989609375\" y=\"25.0\" width=\"89.384375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1481.6817968750001\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1546.3739843750002\" y=\"725.0\" width=\"89.664375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1591.206171875\" y=\"745.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_13</text><rect x=\"1546.3739843750002\" y=\"25.0\" width=\"89.664375\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1591.206171875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1656.0383593750003\" y=\"775.0\" width=\"90.00125000000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1701.0389843750002\" y=\"795.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_14</text><rect x=\"1656.0383593750003\" y=\"25.0\" width=\"90.00125000000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1701.0389843750002\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1756.0396093750003\" y=\"775.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1776.0396093750003\" y=\"795.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">R</text><rect x=\"1796.0396093750003\" y=\"825.0\" width=\"89.56375000000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1840.8214843750002\" y=\"845.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX^xx1_15</text><rect x=\"1796.0396093750003\" y=\"25.0\" width=\"89.56375000000001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1840.8214843750002\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">XX</text><rect x=\"1915.6033593750003\" y=\"75.0\" width=\"78.86441406250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1955.0355664062504\" y=\"95.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_0</text><rect x=\"1915.6033593750003\" y=\"25.0\" width=\"78.86441406250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"1955.0355664062504\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2014.4677734375002\" y=\"125.0\" width=\"78.5012890625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2053.71841796875\" y=\"145.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_1</text><rect x=\"2014.4677734375002\" y=\"25.0\" width=\"78.5012890625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2053.71841796875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2112.9690625000003\" y=\"175.0\" width=\"78.3919140625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2152.1650195312504\" y=\"195.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_2</text><rect x=\"2112.9690625000003\" y=\"25.0\" width=\"78.3919140625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2152.1650195312504\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2211.3609765625\" y=\"225.0\" width=\"78.67191406250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2250.69693359375\" y=\"245.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_3</text><rect x=\"2211.3609765625\" y=\"25.0\" width=\"78.67191406250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2250.69693359375\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2310.032890625\" y=\"275.0\" width=\"79.00878906250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2349.53728515625\" y=\"295.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_4</text><rect x=\"2310.032890625\" y=\"25.0\" width=\"79.00878906250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2349.53728515625\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2409.0416796875\" y=\"325.0\" width=\"78.57128906250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2448.32732421875\" y=\"345.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_5</text><rect x=\"2409.0416796875\" y=\"25.0\" width=\"78.57128906250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2448.32732421875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2507.61296875\" y=\"375.0\" width=\"78.91253906250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2547.0692382812504\" y=\"395.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_6</text><rect x=\"2507.61296875\" y=\"25.0\" width=\"78.91253906250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2547.0692382812504\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2606.5255078125\" y=\"425.0\" width=\"78.5975390625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2645.82427734375\" y=\"445.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_7</text><rect x=\"2606.5255078125\" y=\"25.0\" width=\"78.5975390625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2645.82427734375\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2695.123046875\" y=\"425.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2715.123046875\" y=\"445.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">R</text><rect x=\"2735.123046875\" y=\"475.0\" width=\"78.83597656250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2774.54103515625\" y=\"495.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_8</text><rect x=\"2735.123046875\" y=\"25.0\" width=\"78.83597656250001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2774.54103515625\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2843.9590234375\" y=\"525.0\" width=\"78.80972656250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2883.36388671875\" y=\"545.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_9</text><rect x=\"2843.9590234375\" y=\"25.0\" width=\"78.80972656250002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2883.36388671875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"2942.76875\" y=\"575.0\" width=\"87.77164062500002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2986.6545703125003\" y=\"595.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_10</text><rect x=\"2942.76875\" y=\"25.0\" width=\"87.77164062500002\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"2986.6545703125003\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3050.5403906250003\" y=\"625.0\" width=\"87.408515625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3094.2446484375005\" y=\"645.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_11</text><rect x=\"3050.5403906250003\" y=\"25.0\" width=\"87.408515625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3094.2446484375005\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3157.94890625\" y=\"675.0\" width=\"87.299140625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3201.5984765625003\" y=\"695.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_12</text><rect x=\"3157.94890625\" y=\"25.0\" width=\"87.299140625\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3201.5984765625003\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3265.248046875\" y=\"725.0\" width=\"87.57914062500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3309.0376171875\" y=\"745.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_13</text><rect x=\"3265.248046875\" y=\"25.0\" width=\"87.57914062500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3309.0376171875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3372.8271875\" y=\"775.0\" width=\"87.91601562500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3416.7851953125\" y=\"795.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_14</text><rect x=\"3372.8271875\" y=\"25.0\" width=\"87.91601562500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3416.7851953125\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3480.743203125\" y=\"825.0\" width=\"87.47851562500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3524.4824609375\" y=\"845.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ^zz1_15</text><rect x=\"3480.743203125\" y=\"25.0\" width=\"87.47851562500001\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3524.4824609375\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"14px\" font-family=\"Arial\">ZZ</text><rect x=\"3588.22171875\" y=\"25.0\" width=\"40\" height=\"40\" stroke=\"black\" fill=\"white\" stroke-width=\"1\" /><text x=\"3608.22171875\" y=\"45.0\" dominant-baseline=\"middle\" text-anchor=\"middle\" font-size=\"18px\" font-family=\"Arial\">H</text></svg>"
      ],
      "text/plain": [
       "<cirq.contrib.svg.svg.SVGCircuit at 0x7fbf76a659d0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_circuit, model_readout = create_quantum_model()\n",
    "SVGCircuit(model_circuit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LY7vbY6yfABE"
   },
   "source": [
    "### 2.2 Wrap the model-circuit in a tfq-keras model\n",
    "\n",
    "Build the Keras model with the quantum components. This model is fed the \"quantum data\", from `x_train_circ`, that encodes the classical data. It uses a *Parametrized Quantum Circuit* layer, `tfq.layers.PQC`, to train the model circuit, on the quantum data.\n",
    "\n",
    "To classify these images, <a href=\"https://arxiv.org/pdf/1802.06002.pdf\" class=\"external\">Farhi et al.</a> proposed taking the expectation of a readout qubit in a parameterized circuit. The expectation returns a value between 1 and -1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:20.523804Z",
     "iopub.status.busy": "2021-03-28T11:08:20.523241Z",
     "iopub.status.idle": "2021-03-28T11:08:21.407615Z",
     "shell.execute_reply": "2021-03-28T11:08:21.407983Z"
    },
    "id": "ZYdf_KOxojh0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n"
     ]
    }
   ],
   "source": [
    "# Build the Keras model.\n",
    "qlayer = tfq.layers.PQC(model_circuit, model_readout)\n",
    "print(len(qlayer.get_weights()[0]))\n",
    "\n",
    "model = tf.keras.Sequential([\n",
    "    # The input is the data-circuit, encoded as a tf.string\n",
    "    tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "    # The PQC layer returns the expected value of the readout gate, range [-1,1].\n",
    "    qlayer,\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "jz-FbVc9ojh3"
   },
   "source": [
    "Next, describe the training procedure to the model, using the `compile` method.\n",
    "\n",
    "Since the the expected readout is in the range `[-1,1]`, optimizing the hinge loss is a somewhat natural fit. \n",
    "\n",
    "Note: Another valid approach would be to shift the output range to `[0,1]`, and treat it as the probability the model assigns to class `3`. This could be used with a standard a `tf.losses.BinaryCrossentropy` loss.\n",
    "\n",
    "To use the hinge loss here you need to make two small adjustments. First convert the labels, `y_train_nocon`, from boolean to `[-1,1]`, as expected by the hinge loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:21.412447Z",
     "iopub.status.busy": "2021-03-28T11:08:21.411873Z",
     "iopub.status.idle": "2021-03-28T11:08:21.413776Z",
     "shell.execute_reply": "2021-03-28T11:08:21.413330Z"
    },
    "id": "CgMNkC1Fojh5"
   },
   "outputs": [],
   "source": [
    "y_train_hinge = 2.0*y_train_nocon-1.0\n",
    "y_test_hinge = 2.0*y_test-1.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5nwnveDiojh7"
   },
   "source": [
    "Second, use a custiom `hinge_accuracy` metric that correctly handles `[-1, 1]` as the `y_true` labels argument. \n",
    "`tf.losses.BinaryAccuracy(threshold=0.0)` expects `y_true` to be a boolean, and so can't be used with hinge loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:21.418475Z",
     "iopub.status.busy": "2021-03-28T11:08:21.417678Z",
     "iopub.status.idle": "2021-03-28T11:08:21.419361Z",
     "shell.execute_reply": "2021-03-28T11:08:21.419724Z"
    },
    "id": "3XKtZ_TEojh8"
   },
   "outputs": [],
   "source": [
    "def hinge_accuracy(y_true, y_pred):\n",
    "    y_true = tf.squeeze(y_true) > 0.0\n",
    "    y_pred = tf.squeeze(y_pred) > 0.0\n",
    "    result = tf.cast(y_true == y_pred, tf.float32)\n",
    "\n",
    "    return tf.reduce_mean(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:21.431709Z",
     "iopub.status.busy": "2021-03-28T11:08:21.426355Z",
     "iopub.status.idle": "2021-03-28T11:08:21.440305Z",
     "shell.execute_reply": "2021-03-28T11:08:21.440646Z"
    },
    "id": "FlpETlLRojiA"
   },
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss=tf.keras.losses.Hinge(),\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    metrics=[hinge_accuracy])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:21.444767Z",
     "iopub.status.busy": "2021-03-28T11:08:21.444211Z",
     "iopub.status.idle": "2021-03-28T11:08:21.447733Z",
     "shell.execute_reply": "2021-03-28T11:08:21.448105Z"
    },
    "id": "jkHq2RstojiC"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "pqc (PQC)                    (None, 1)                 32        \n",
      "=================================================================\n",
      "Total params: 32\n",
      "Trainable params: 32\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lsuOzDYblA9s"
   },
   "source": [
    "### Train the quantum model\n",
    "\n",
    "Now train the model—this takes about 45 min. If you don't want to wait that long, use a small subset of the data (set `NUM_EXAMPLES=500`, below). This doesn't really affect the model's progress during training (it only has 32 parameters, and doesn't need much data to constrain these). Using fewer examples just ends training earlier (5min), but runs long enough to show that it is making progress in the validation logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:21.451886Z",
     "iopub.status.busy": "2021-03-28T11:08:21.451344Z",
     "iopub.status.idle": "2021-03-28T11:08:21.452965Z",
     "shell.execute_reply": "2021-03-28T11:08:21.453319Z"
    },
    "id": "n8vuQpSLlBV2"
   },
   "outputs": [],
   "source": [
    "EPOCHS = 6\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "NUM_EXAMPLES = len(x_train_tfcirc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:21.456809Z",
     "iopub.status.busy": "2021-03-28T11:08:21.456272Z",
     "iopub.status.idle": "2021-03-28T11:08:21.458050Z",
     "shell.execute_reply": "2021-03-28T11:08:21.458454Z"
    },
    "id": "qJnNG-3JojiI"
   },
   "outputs": [],
   "source": [
    "x_train_tfcirc_sub = x_train_tfcirc[:NUM_EXAMPLES]\n",
    "y_train_hinge_sub = y_train_hinge[:NUM_EXAMPLES]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QMSdgGC1GL7D"
   },
   "source": [
    "Training this model to convergence should achieve >85% accuracy on the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:08:21.462580Z",
     "iopub.status.busy": "2021-03-28T11:08:21.462013Z",
     "iopub.status.idle": "2021-03-28T11:11:12.423522Z",
     "shell.execute_reply": "2021-03-28T11:11:12.422974Z"
    },
    "id": "Ya9qP3KkojiM"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 16/324 [>.............................] - ETA: 6:01:42 - loss: 0.9972 - hinge_accuracy: 0.5378"
     ]
    }
   ],
   "source": [
    "for i in range(EPOCHS):\n",
    "    # HACK - build new quantum circuit for each epoch and copy over the weights from the old one\n",
    "    model_circuit, model_readout = create_quantum_model()\n",
    "    \n",
    "    if i == 0:\n",
    "        qlayer = tfq.layers.NoisyPQC(model_circuit, model_readout, repetitions=1, sample_based=False)\n",
    "    else:\n",
    "        qlayer_new = tfq.layers.NoisyPQC(model_circuit, model_readout, repetitions=1, sample_based=False,\n",
    "                                         initializer=tf.keras.initializers.Zeros)\n",
    "        qlayer_new.set_weights(qlayer.get_weights())\n",
    "        qlayer = qlayer_new\n",
    "        \n",
    "    model = tf.keras.Sequential([\n",
    "        tf.keras.layers.Input(shape=(), dtype=tf.string),\n",
    "        qlayer,\n",
    "    ])\n",
    "    model.compile(\n",
    "        loss=tf.keras.losses.Hinge(),\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        metrics=[hinge_accuracy])\n",
    "    \n",
    "    # Now fit the model for this epoch\n",
    "    model.fit(\n",
    "          x_train_tfcirc_sub, y_train_hinge_sub,\n",
    "          batch_size=32,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test_tfcirc, y_test_hinge))\n",
    "\n",
    "qnn_results = model.evaluate(x_test_tfcirc, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3ER7B7aaojiP"
   },
   "source": [
    "Note: The training accuracy reports the average over the epoch. The validation accuracy is evaluated at the end of each epoch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8952YvuWGL7J"
   },
   "source": [
    "## 3. Classical neural network\n",
    "\n",
    "While the quantum neural network works for this simplified MNIST problem, a basic classical neural network can easily outperform a QNN on this task. After a single epoch, a classical neural network can achieve >98% accuracy on the holdout set.\n",
    "\n",
    "In the following example, a classical neural network is used for for the 3-6 classification problem using the entire 28x28 image instead of subsampling the image. This easily converges to nearly 100% accuracy of the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:11:12.433307Z",
     "iopub.status.busy": "2021-03-28T11:11:12.432717Z",
     "iopub.status.idle": "2021-03-28T11:11:12.503030Z",
     "shell.execute_reply": "2021-03-28T11:11:12.503380Z"
    },
    "id": "pZofEHhLGL7L"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 24, 24, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 12, 12, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 9216)              0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 128)               1179776   \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 1,198,721\n",
      "Trainable params: 1,198,721\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Conv2D(32, [3, 3], activation='relu', input_shape=(28,28,1)))\n",
    "    model.add(tf.keras.layers.Conv2D(64, [3, 3], activation='relu'))\n",
    "    model.add(tf.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
    "    model.add(tf.keras.layers.Dropout(0.25))\n",
    "    model.add(tf.keras.layers.Flatten())\n",
    "    model.add(tf.keras.layers.Dense(128, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dropout(0.5))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:11:12.508061Z",
     "iopub.status.busy": "2021-03-28T11:11:12.507473Z",
     "iopub.status.idle": "2021-03-28T11:11:15.974548Z",
     "shell.execute_reply": "2021-03-28T11:11:15.973986Z"
    },
    "id": "CiAJl7sZojiU"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "95/95 [==============================] - 3s 29ms/step - loss: 0.0417 - accuracy: 0.9837 - val_loss: 0.0033 - val_accuracy: 0.9995\n",
      "62/62 [==============================] - 0s 3ms/step - loss: 0.0033 - accuracy: 0.9995\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train,\n",
    "          y_train,\n",
    "          batch_size=128,\n",
    "          epochs=1,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))\n",
    "\n",
    "cnn_results = model.evaluate(x_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X5-5BVJaojiZ"
   },
   "source": [
    "The above model has nearly 1.2M parameters. For a more fair comparison, try a 37-parameter model, on the subsampled images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:11:15.982573Z",
     "iopub.status.busy": "2021-03-28T11:11:15.981920Z",
     "iopub.status.idle": "2021-03-28T11:11:16.179577Z",
     "shell.execute_reply": "2021-03-28T11:11:16.179051Z"
    },
    "id": "70TOM6r-ojiZ",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 2)                 34        \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 3         \n",
      "=================================================================\n",
      "Total params: 37\n",
      "Trainable params: 37\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def create_fair_classical_model():\n",
    "    # A simple model based off LeNet from https://keras.io/examples/mnist_cnn/\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(tf.keras.layers.Flatten(input_shape=(4,4,1)))\n",
    "    model.add(tf.keras.layers.Dense(2, activation='relu'))\n",
    "    model.add(tf.keras.layers.Dense(1))\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_fair_classical_model()\n",
    "model.compile(loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:11:16.184431Z",
     "iopub.status.busy": "2021-03-28T11:11:16.183888Z",
     "iopub.status.idle": "2021-03-28T11:11:18.230890Z",
     "shell.execute_reply": "2021-03-28T11:11:18.230436Z"
    },
    "id": "lA_Fx-8gojid"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "81/81 - 0s - loss: 0.6167 - accuracy: 0.6339 - val_loss: 0.5685 - val_accuracy: 0.6784\n",
      "Epoch 2/20\n",
      "81/81 - 0s - loss: 0.5446 - accuracy: 0.7009 - val_loss: 0.4977 - val_accuracy: 0.7139\n",
      "Epoch 3/20\n",
      "81/81 - 0s - loss: 0.4719 - accuracy: 0.7727 - val_loss: 0.4305 - val_accuracy: 0.8125\n",
      "Epoch 4/20\n",
      "81/81 - 0s - loss: 0.4104 - accuracy: 0.8341 - val_loss: 0.3773 - val_accuracy: 0.8384\n",
      "Epoch 5/20\n",
      "81/81 - 0s - loss: 0.3639 - accuracy: 0.8416 - val_loss: 0.3375 - val_accuracy: 0.8425\n",
      "Epoch 6/20\n",
      "81/81 - 0s - loss: 0.3292 - accuracy: 0.8537 - val_loss: 0.3084 - val_accuracy: 0.8521\n",
      "Epoch 7/20\n",
      "81/81 - 0s - loss: 0.3038 - accuracy: 0.8585 - val_loss: 0.2868 - val_accuracy: 0.8608\n",
      "Epoch 8/20\n",
      "81/81 - 0s - loss: 0.2851 - accuracy: 0.8633 - val_loss: 0.2706 - val_accuracy: 0.8618\n",
      "Epoch 9/20\n",
      "81/81 - 0s - loss: 0.2710 - accuracy: 0.8665 - val_loss: 0.2588 - val_accuracy: 0.8633\n",
      "Epoch 10/20\n",
      "81/81 - 0s - loss: 0.2604 - accuracy: 0.8680 - val_loss: 0.2501 - val_accuracy: 0.8633\n",
      "Epoch 11/20\n",
      "81/81 - 0s - loss: 0.2524 - accuracy: 0.8697 - val_loss: 0.2436 - val_accuracy: 0.8638\n",
      "Epoch 12/20\n",
      "81/81 - 0s - loss: 0.2462 - accuracy: 0.8722 - val_loss: 0.2385 - val_accuracy: 0.8638\n",
      "Epoch 13/20\n",
      "81/81 - 0s - loss: 0.2413 - accuracy: 0.8732 - val_loss: 0.2347 - val_accuracy: 0.8653\n",
      "Epoch 14/20\n",
      "81/81 - 0s - loss: 0.2374 - accuracy: 0.8734 - val_loss: 0.2316 - val_accuracy: 0.8653\n",
      "Epoch 15/20\n",
      "81/81 - 0s - loss: 0.2343 - accuracy: 0.8909 - val_loss: 0.2290 - val_accuracy: 0.9121\n",
      "Epoch 16/20\n",
      "81/81 - 0s - loss: 0.2318 - accuracy: 0.8953 - val_loss: 0.2272 - val_accuracy: 0.9131\n",
      "Epoch 17/20\n",
      "81/81 - 0s - loss: 0.2297 - accuracy: 0.9004 - val_loss: 0.2255 - val_accuracy: 0.9141\n",
      "Epoch 18/20\n",
      "81/81 - 0s - loss: 0.2280 - accuracy: 0.9013 - val_loss: 0.2246 - val_accuracy: 0.9141\n",
      "Epoch 19/20\n",
      "81/81 - 0s - loss: 0.2266 - accuracy: 0.9029 - val_loss: 0.2231 - val_accuracy: 0.9141\n",
      "Epoch 20/20\n",
      "81/81 - 0s - loss: 0.2254 - accuracy: 0.9034 - val_loss: 0.2223 - val_accuracy: 0.9141\n",
      "62/62 [==============================] - 0s 549us/step - loss: 0.2223 - accuracy: 0.9141\n"
     ]
    }
   ],
   "source": [
    "model.fit(x_train_bin,\n",
    "          y_train_nocon,\n",
    "          batch_size=128,\n",
    "          epochs=20,\n",
    "          verbose=2,\n",
    "          validation_data=(x_test_bin, y_test))\n",
    "\n",
    "fair_nn_results = model.evaluate(x_test_bin, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "RH3mam7EGL7N"
   },
   "source": [
    "## 4. Comparison\n",
    "\n",
    "Higher resolution input and a more powerful model make this problem easy for the CNN. While a classical model of similar power (~32 parameters) trains to a similar accuracy in a fraction of the time. One way or the other, the classical neural network easily outperforms the quantum neural network. For classical data, it is difficult to beat a classical neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "execution": {
     "iopub.execute_input": "2021-03-28T11:11:18.235797Z",
     "iopub.status.busy": "2021-03-28T11:11:18.235221Z",
     "iopub.status.idle": "2021-03-28T11:11:18.331050Z",
     "shell.execute_reply": "2021-03-28T11:11:18.330512Z"
    },
    "id": "NOMeN7pMGL7P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kbuilder/.local/lib/python3.6/site-packages/seaborn/_decorators.py:43: FutureWarning: Pass the following variables as keyword args: x, y. From version 0.12, the only valid positional argument will be `data`, and passing other arguments without an explicit keyword will result in an error or misinterpretation.\n",
      "  FutureWarning\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "qnn_accuracy = qnn_results[1]\n",
    "cnn_accuracy = cnn_results[1]\n",
    "fair_nn_accuracy = fair_nn_results[1]\n",
    "\n",
    "sns.barplot([\"Quantum\", \"Classical, full\", \"Classical, fair\"],\n",
    "            [qnn_accuracy, cnn_accuracy, fair_nn_accuracy])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "mnist.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
